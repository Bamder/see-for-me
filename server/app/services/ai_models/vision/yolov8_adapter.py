"""
YOLOv8n æ¨¡å‹é€‚é…å™¨
æ”¯æŒ ONNX ä¼˜åŒ–æ¨ç†ï¼Œç›®æ ‡æ¨ç†æ—¶é—´ â‰¤200ms
"""

import os
import cv2
import numpy as np
from typing import List, Dict, Any, Optional
import time
import logging
from pathlib import Path
import yaml

try:
    import torch
    TORCH_AVAILABLE = True
    # ä¿®å¤ PyTorch 2.6+ å…¼å®¹æ€§é—®é¢˜ï¼šå…¨å±€æ›¿æ¢ torch.load
    # PyTorch 2.6 é»˜è®¤ weights_only=Trueï¼Œä½† ultralytics éœ€è¦åŠ è½½è‡ªå®šä¹‰ç±»
    if hasattr(torch, 'load'):
        import functools
        import inspect
        _original_torch_load = torch.load
        
        @functools.wraps(_original_torch_load)
        def _patched_torch_load(*args, **kwargs):
            # å¯¹äº ultralytics æ¨¡å‹æ–‡ä»¶ï¼Œè‡ªåŠ¨è®¾ç½® weights_only=False
            if 'weights_only' not in kwargs:
                # æ£€æŸ¥è°ƒç”¨æ ˆä¸­æ˜¯å¦æœ‰ ultralytics æ¨¡å—
                stack = inspect.stack()
                is_ultralytics_call = any(
                    'ultralytics' in str(frame.filename) for frame in stack[1:]
                )
                # æˆ–è€…æ£€æŸ¥æ–‡ä»¶è·¯å¾„æ˜¯å¦åŒ…å« .ptï¼ˆPyTorch æ¨¡å‹æ–‡ä»¶ï¼‰
                is_pt_file = (
                    args and 
                    isinstance(args[0], (str, bytes)) and 
                    str(args[0]).endswith('.pt')
                )
                if is_ultralytics_call or is_pt_file:
                    kwargs['weights_only'] = False
            return _original_torch_load(*args, **kwargs)
        
        # å…¨å±€æ›¿æ¢ torch.loadï¼ˆå½±å“æ‰€æœ‰æ¨¡å—ï¼ŒåŒ…æ‹¬ ultralyticsï¼‰
        torch.load = _patched_torch_load
except ImportError:
    TORCH_AVAILABLE = False

try:
    from ultralytics import YOLO
    ULTRALYTICS_AVAILABLE = True
except ImportError:
    ULTRALYTICS_AVAILABLE = False
    logging.warning("ultralytics not available, ONNX mode will be used")

try:
    import onnxruntime as ort
    ONNXRUNTIME_AVAILABLE = True
    # åœ¨æ¨¡å—çº§åˆ«æŠ‘åˆ¶ ONNX Runtime çš„ CUDA è­¦å‘Š
    import logging
    import os
    
    # æ–¹æ³•1: è®¾ç½®æ—¥å¿—çº§åˆ«
    onnx_logger = logging.getLogger("onnxruntime")
    onnx_logger.setLevel(logging.ERROR)  # åªæ˜¾ç¤ºé”™è¯¯ï¼Œä¸æ˜¾ç¤ºè­¦å‘Šå’Œä¿¡æ¯
    
    # æ–¹æ³•2: è®¾ç½®ç¯å¢ƒå˜é‡ï¼ŒæŠ‘åˆ¶ ONNX Runtime çš„æ—¥å¿—è¾“å‡º
    # ORT_LOGGING_LEVEL: 0=VERBOSE, 1=INFO, 2=WARNING, 3=ERROR, 4=FATAL
    # è®¾ç½®ä¸º 3 (ERROR) å¯ä»¥æŠ‘åˆ¶è­¦å‘Šä¿¡æ¯
    if "ORT_LOGGING_LEVEL" not in os.environ:
        os.environ["ORT_LOGGING_LEVEL"] = "3"
    
    # æ–¹æ³•3: é»˜è®¤åªä½¿ç”¨ CPUï¼Œé¿å… CUDA ç›¸å…³çš„è­¦å‘Š
    # å¦‚æœéœ€è¦ CUDAï¼Œå¯ä»¥è®¾ç½®ç¯å¢ƒå˜é‡ ORT_USE_CUDA=1
    if "ORT_USE_CUDA" not in os.environ:
        os.environ["ORT_USE_CUDA"] = "0"  # é»˜è®¤ä½¿ç”¨ CPU
    # æ³¨æ„ï¼šå³ä½¿è®¾ç½®äº†ç¯å¢ƒå˜é‡ï¼ŒONNX Runtime ä»å¯èƒ½è¾“å‡º CUDA è­¦å‘Š
    # è¿™æ˜¯ ONNX Runtime åº“çš„é™åˆ¶ï¼Œæ— æ³•å®Œå…¨æŠ‘åˆ¶ C++ å±‚çš„è­¦å‘Š
except ImportError:
    ONNXRUNTIME_AVAILABLE = False
    logging.warning("onnxruntime not available, falling back to PyTorch")

from .base_vision import BaseVisionModel

logger = logging.getLogger(__name__)


class YOLOv8nAdapter(BaseVisionModel):
    """YOLOv8n æ¨¡å‹é€‚é…å™¨ï¼Œæ”¯æŒ ONNX ä¼˜åŒ–æ¨ç†"""
    
    def __init__(
        self, 
        model_path: Optional[str] = None,
        use_onnx: bool = True,
        confidence_threshold: float = 0.25,
        iou_threshold: float = 0.45,
        class_mapping_file: Optional[str] = None,
        use_chinese: bool = True
    ):
        """
        åˆå§‹åŒ– YOLOv8n é€‚é…å™¨
        
        Args:
            model_path: æ¨¡å‹æ–‡ä»¶è·¯å¾„ï¼Œå¦‚æœä¸º None åˆ™ä½¿ç”¨é»˜è®¤ yolov8n.pt
            use_onnx: æ˜¯å¦ä½¿ç”¨ ONNX ä¼˜åŒ–æ¨ç†
            confidence_threshold: ç½®ä¿¡åº¦é˜ˆå€¼
            iou_threshold: IOU é˜ˆå€¼
            class_mapping_file: ä¸­è‹±æ–‡å¯¹ç…§é…ç½®æ–‡ä»¶è·¯å¾„ï¼ŒNone è¡¨ç¤ºä½¿ç”¨é»˜è®¤è·¯å¾„
            use_chinese: æ˜¯å¦åœ¨è¿”å›ç»“æœä¸­ä½¿ç”¨ä¸­æ–‡åç§°
        """
        self.model_path = model_path or "yolov8n.pt"
        # ä¿ç•™åŸå§‹çš„ use_onnx å€¼ï¼Œç”¨äºå†³å®šæ˜¯å¦å°è¯• ONNX
        self._prefer_onnx = use_onnx
        # å®é™…ä½¿ç”¨çš„æ¨¡å¼ï¼Œä¼šåœ¨ _load_model ä¸­æ ¹æ®å°è¯•ç»“æœè®¾ç½®
        self.use_onnx = False
        self.confidence_threshold = confidence_threshold
        self.iou_threshold = iou_threshold
        self.use_chinese = use_chinese
        
        self.model = None
        self.ort_session = None
        self.input_name = None
        self.output_names = None
        self.class_names = None
        self.input_shape = None
        self.model_source = None  # æ¨¡å‹æ¥æºï¼ˆæ–‡ä»¶è·¯å¾„æˆ–æ¥æºè¯´æ˜ï¼‰
        self.execution_provider = None  # æ‰§è¡Œæä¾›è€…ï¼ˆCPU/CUDAï¼‰
        
        # åŠ è½½ä¸­è‹±æ–‡å¯¹ç…§é…ç½®
        self.class_mapping = {}  # è‹±æ–‡ -> ä¸­æ–‡
        self.class_mapping_file = class_mapping_file
        self._load_class_mapping()
        
        self._load_model()
        # ä¸åœ¨åˆå§‹åŒ–æ—¶è‡ªåŠ¨æ‰“å°ï¼Œç”±è°ƒç”¨è€…å†³å®šæ˜¯å¦æ‰“å°
    
    def _load_model(self):
        """åŠ è½½æ¨¡å‹ï¼Œæ”¯æŒ ONNX ä¼˜åŒ–ï¼Œå¤±è´¥åè‡ªåŠ¨å›é€€åˆ° PyTorch"""
        # å¦‚æœé…ç½®äº†ä½¿ç”¨ ONNX ä¸” ONNX Runtime å¯ç”¨ï¼Œå…ˆå°è¯• ONNX
        if self._prefer_onnx and ONNXRUNTIME_AVAILABLE:
            try:
                logger.info("å°è¯•åŠ è½½ ONNX æ¨¡å‹...")
                self._load_onnx_model()
                self.use_onnx = True
                logger.info(f"YOLOv8n æ¨¡å‹åŠ è½½æˆåŠŸ (ONNX æ¨¡å¼)")
                return
            except Exception as e:
                logger.warning(f"ONNX æ¨¡å¼åŠ è½½å¤±è´¥: {e}")
                logger.info("ONNX æ¨¡å¼å¤±è´¥ï¼Œå°è¯•å›é€€åˆ° PyTorch æ¨¡å¼")
                # ç»§ç»­æ‰§è¡Œï¼Œå°è¯• PyTorch æ¨¡å¼
        elif self._prefer_onnx and not ONNXRUNTIME_AVAILABLE:
            logger.warning("é…ç½®äº†ä½¿ç”¨ ONNXï¼Œä½† ONNX Runtime ä¸å¯ç”¨ï¼Œç›´æ¥ä½¿ç”¨ PyTorch æ¨¡å¼")
        
        # å°è¯• PyTorch æ¨¡å¼
        if ULTRALYTICS_AVAILABLE:
            try:
                self._load_pytorch_model()
                self.use_onnx = False
                logger.info(f"YOLOv8n æ¨¡å‹åŠ è½½æˆåŠŸ (PyTorch æ¨¡å¼)")
            except Exception as pytorch_error:
                logger.error(f"PyTorch æ¨¡å¼ä¹Ÿå¤±è´¥: {pytorch_error}")
                raise RuntimeError(
                    f"æ— æ³•åŠ è½½æ¨¡å‹ã€‚\n"
                    f"{'ONNX æ¨¡å¼å¤±è´¥ï¼Œ' if self._prefer_onnx and ONNXRUNTIME_AVAILABLE else ''}"
                    f"PyTorch æ¨¡å¼ä¹Ÿå¤±è´¥: {pytorch_error}\n"
                    f"è¯·æ£€æŸ¥ ultralytics åº“çš„å®‰è£…å’Œç‰ˆæœ¬å…¼å®¹æ€§ã€‚"
                ) from pytorch_error
        else:
            raise RuntimeError(
                "æ— æ³•åŠ è½½æ¨¡å‹ï¼šultralytics åº“æœªå®‰è£…ï¼Œä¸” ONNX æ¨¡å¼ä¸å¯ç”¨ã€‚\n"
                "è¯·å®‰è£… ultralytics åº“ï¼špip install ultralytics"
            )
    
    def _load_onnx_model(self):
        """åŠ è½½ ONNX æ¨¡å‹"""
        # å¦‚æœ model_path å·²ç»æ˜¯ .onnx æ–‡ä»¶ï¼Œç›´æ¥ä½¿ç”¨
        # å¦åˆ™å°è¯•å°† .pt æ›¿æ¢ä¸º .onnx
        if self.model_path.endswith('.onnx'):
            onnx_path = self.model_path
        else:
            onnx_path = self.model_path.replace('.pt', '.onnx')
        
        # ç¡®ä¿è·¯å¾„æ˜¯ç»å¯¹è·¯å¾„ï¼ˆç›¸å¯¹äº server ç›®å½•ï¼‰
        if not os.path.isabs(onnx_path):
            # å°è¯•ä» server ç›®å½•è§£æ
            server_dir = Path(__file__).parent.parent.parent.parent
            onnx_path_abs = server_dir / onnx_path
            if onnx_path_abs.exists():
                onnx_path = str(onnx_path_abs)
            # å¦‚æœè¿˜æ˜¯ç›¸å¯¹è·¯å¾„ï¼Œå°è¯•å½“å‰å·¥ä½œç›®å½•
            elif not os.path.exists(onnx_path):
                # ä¿æŒåŸè·¯å¾„ï¼Œè®©åç»­é€»è¾‘å¤„ç†
                pass
        
        # å¦‚æœ ONNX æ–‡ä»¶ä¸å­˜åœ¨ï¼Œå°è¯•å¯¼å‡º
        if not os.path.exists(onnx_path):
            if ULTRALYTICS_AVAILABLE:
                logger.info(f"ONNX æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨ï¼Œå°è¯•ä» PyTorch æ¨¡å‹å¯¼å‡º: {onnx_path}")
                try:
                    self._export_to_onnx(onnx_path)
                    self.model_source = f"ä» {self.model_path} å¯¼å‡º"
                except Exception as export_error:
                    logger.error(f"æ— æ³•å¯¼å‡º ONNX æ¨¡å‹: {export_error}")
                    # æ£€æŸ¥æ˜¯å¦æ˜¯ç¼ºå°‘ onnxscript çš„é”™è¯¯
                    error_msg = str(export_error).lower()
                    if 'onnxscript' in error_msg or 'no module named' in error_msg:
                        raise FileNotFoundError(
                            f"ONNX æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨ä¸”æ— æ³•ä» PyTorch æ¨¡å‹å¯¼å‡ºã€‚\n"
                            f"é”™è¯¯è¯¦æƒ…: {export_error}\n"
                            f"è§£å†³æ–¹æ¡ˆï¼š\n"
                            f"1. å®‰è£…ç¼ºå¤±çš„ä¾èµ–: pip install onnxscript\n"
                            f"2. æˆ–é‡æ–°å®‰è£… ultralytics: pip install --upgrade ultralytics\n"
                            f"3. æ‰‹åŠ¨ä¸‹è½½æˆ–è½¬æ¢ ONNX æ¨¡å‹æ–‡ä»¶åˆ°: {onnx_path}\n"
                            f"4. æˆ–ä½¿ç”¨ PyTorch æ¨¡å¼ï¼ˆè®¾ç½® use_onnx=Falseï¼‰"
                        ) from export_error
                    else:
                        raise FileNotFoundError(
                            f"ONNX æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨ä¸”æ— æ³•ä» PyTorch æ¨¡å‹å¯¼å‡ºã€‚\n"
                            f"é”™è¯¯è¯¦æƒ…: {export_error}\n"
                            f"è§£å†³æ–¹æ¡ˆï¼š\n"
                            f"1. æ‰‹åŠ¨ä¸‹è½½æˆ–è½¬æ¢ ONNX æ¨¡å‹æ–‡ä»¶åˆ°: {onnx_path}\n"
                            f"2. æ£€æŸ¥ ultralytics åº“çš„å®‰è£…å’Œç‰ˆæœ¬å…¼å®¹æ€§\n"
                            f"3. ç¡®ä¿æ‰€æœ‰å¿…éœ€çš„ä¾èµ–æ¨¡å—å·²å®‰è£…ï¼ˆåŒ…æ‹¬ onnxscriptï¼‰\n"
                            f"4. æˆ–ä½¿ç”¨ PyTorch æ¨¡å¼ï¼ˆè®¾ç½® use_onnx=Falseï¼‰"
                        ) from export_error
            else:
                raise FileNotFoundError(
                    f"ONNX æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {onnx_path}\n"
                    f"ä¸” ultralytics åº“æœªå®‰è£…ï¼Œæ— æ³•è‡ªåŠ¨å¯¼å‡ºã€‚\n"
                    f"è¯·æ‰‹åŠ¨æä¾› ONNX æ¨¡å‹æ–‡ä»¶ã€‚"
                )
        else:
            self.model_source = f"æœ¬åœ°æ–‡ä»¶: {onnx_path}"
        
        # åˆ›å»º ONNX Runtime ä¼šè¯
        # ç›´æ¥ä½¿ç”¨ CPUï¼Œé¿å… CUDA è­¦å‘Šä¿¡æ¯
        # å¦‚æœç³»ç»Ÿæœ‰ CUDA æ”¯æŒï¼Œå¯ä»¥é€šè¿‡ç¯å¢ƒå˜é‡å¯ç”¨ï¼šORT_USE_CUDA=1
        providers = ['CPUExecutionProvider']
        
        # åˆ›å»º SessionOptions æ¥æŠ‘åˆ¶æ—¥å¿—è¾“å‡º
        sess_options = ort.SessionOptions()
        sess_options.log_severity_level = 3  # 3 = ERROR, åªæ˜¾ç¤ºé”™è¯¯ï¼Œä¸æ˜¾ç¤ºè­¦å‘Š
        
        # æ£€æŸ¥æ˜¯å¦é€šè¿‡ç¯å¢ƒå˜é‡å¯ç”¨äº† CUDA
        use_cuda = os.environ.get("ORT_USE_CUDA", "0").lower() in ("1", "true", "yes")
        
        if use_cuda:
            # ç”¨æˆ·æ˜ç¡®è¦æ±‚ä½¿ç”¨ CUDA
            try:
                available_providers = ort.get_available_providers()
                if 'CUDAExecutionProvider' in available_providers:
                    providers = ['CUDAExecutionProvider', 'CPUExecutionProvider']
                    logger.info("ONNX Runtime å°†ä½¿ç”¨ CUDA åŠ é€Ÿï¼ˆé€šè¿‡ç¯å¢ƒå˜é‡å¯ç”¨ï¼‰")
            except Exception as e:
                logger.debug(f"æ— æ³•æ£€æµ‹ CUDA æä¾›è€…: {e}")
        
        # åˆ›å»ºä¼šè¯ï¼ˆä½¿ç”¨ SessionOptions æŠ‘åˆ¶æ—¥å¿—ï¼‰
        self.ort_session = ort.InferenceSession(
            onnx_path,
            providers=providers,
            sess_options=sess_options
        )
        
        # è®°å½•å®é™…ä½¿ç”¨çš„æ‰§è¡Œæä¾›è€…
        actual_providers = self.ort_session.get_providers()
        if 'CUDAExecutionProvider' in actual_providers:
            self.execution_provider = "CUDA"
            logger.info("ONNX Runtime ä¼šè¯åˆ›å»ºæˆåŠŸï¼ˆä½¿ç”¨ CUDA åŠ é€Ÿï¼‰")
        else:
            self.execution_provider = "CPU"
            logger.info("ONNX Runtime ä¼šè¯åˆ›å»ºæˆåŠŸï¼ˆä½¿ç”¨ CPUï¼‰")
        
        # è·å–è¾“å…¥è¾“å‡ºä¿¡æ¯
        self.input_name = self.ort_session.get_inputs()[0].name
        self.output_names = [output.name for output in self.ort_session.get_outputs()]
        self.input_shape = self.ort_session.get_inputs()[0].shape
        
        # è·å–ç±»åˆ«åç§°ï¼šåœ¨ ONNX æ¨¡å¼ä¸‹ï¼Œç›´æ¥ä¾èµ–é…ç½®æ–‡ä»¶æä¾›çš„ COCO ç±»åˆ«æ˜ å°„ï¼Œ
        # ä¸å†å°è¯•åŠ è½½ PyTorch æ¨¡å‹è¯»å– namesï¼Œé¿å…å›  ultralytics ç‰ˆæœ¬å·®å¼‚äº§ç”Ÿé¢å¤–æŠ¥é”™ã€‚
        try:
            self.class_names = self._get_default_coco_names()
            logger.info(f"ä½¿ç”¨é…ç½®æ–‡ä»¶æä¾›çš„ COCO ç±»åˆ«æ˜ å°„ï¼Œå…± {len(self.class_names)} ä¸ªç±»åˆ«")
        except Exception as e:
            # è‹¥æ˜ å°„ç¼ºå¤±æˆ–é…ç½®æ–‡ä»¶å¼‚å¸¸ï¼Œç›´æ¥æŠ›å‡ºé”™è¯¯ï¼Œæç¤ºç”¨æˆ·è¡¥é½é…ç½®
            logger.error(f"åŠ è½½ COCO ç±»åˆ«æ˜ å°„å¤±è´¥: {e}")
            raise
    
    def _ensure_model_in_project_dir(self) -> str:
        """
        ç¡®ä¿ PyTorch æ¨¡å‹æ–‡ä»¶åœ¨é¡¹ç›®ç›®å½•ï¼ˆserver/modelsï¼‰ä¸­
        å¦‚æœæ¨¡å‹ä¸å­˜åœ¨ï¼Œä¼šå…ˆä¸‹è½½åˆ°é¡¹ç›®ç›®å½•ï¼Œè€Œä¸æ˜¯ ultralytics çš„é»˜è®¤ç¼“å­˜ç›®å½•
        
        Returns:
            æ¨¡å‹æ–‡ä»¶çš„ç»å¯¹è·¯å¾„
        """
        # è·å– server ç›®å½•
        server_dir = Path(__file__).parent.parent.parent.parent
        
        # ç¡®å®šç›®æ ‡è·¯å¾„ï¼ˆserver/models/yolov8n.ptï¼‰
        if os.path.isabs(self.model_path):
            target_path = Path(self.model_path)
        else:
            # å¦‚æœæ˜¯ç›¸å¯¹è·¯å¾„ï¼Œè§£æä¸º server/models/ ä¸‹çš„æ–‡ä»¶
            if self.model_path.startswith('models/'):
                target_path = server_dir / self.model_path
            else:
                # å¦‚æœåªæ˜¯æ–‡ä»¶åï¼ˆå¦‚ "yolov8n.pt"ï¼‰ï¼Œæ”¾åœ¨ models ç›®å½•
                target_path = server_dir / "models" / self.model_path
        
        # ç¡®ä¿ models ç›®å½•å­˜åœ¨
        target_path.parent.mkdir(parents=True, exist_ok=True)
        
        # å¦‚æœç›®æ ‡æ–‡ä»¶å·²å­˜åœ¨ï¼Œç›´æ¥è¿”å›
        if target_path.exists():
            logger.info(f"ä½¿ç”¨æœ¬åœ°æ¨¡å‹æ–‡ä»¶: {target_path}")
            return str(target_path)
        
        # å¦‚æœæ–‡ä»¶ä¸å­˜åœ¨ï¼Œéœ€è¦ä¸‹è½½
        logger.info(f"æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨ï¼Œå°†ä¸‹è½½åˆ°: {target_path}")
        
        # ä½¿ç”¨ä¸´æ—¶è·¯å¾„è®© ultralytics ä¸‹è½½ï¼Œç„¶åç§»åŠ¨åˆ°ç›®æ ‡ä½ç½®
        # å…ˆå°è¯•ç›´æ¥ä¸‹è½½åˆ°ç›®æ ‡ä½ç½®
        try:
            # ä¸´æ—¶ä¿®æ”¹å·¥ä½œç›®å½•åˆ° models ç›®å½•ï¼Œè®© ultralytics ä¸‹è½½åˆ°æ­£ç¡®ä½ç½®
            original_cwd = os.getcwd()
            try:
                os.chdir(str(target_path.parent))
                # ä½¿ç”¨ç›¸å¯¹è·¯å¾„è®© ultralytics ä¸‹è½½åˆ°å½“å‰ç›®å½•
                model_name = target_path.name
                temp_model = YOLO(model_name)
                # ä¸‹è½½å®Œæˆåï¼Œæ£€æŸ¥æ–‡ä»¶æ˜¯å¦åœ¨æ­£ç¡®ä½ç½®
                if target_path.exists():
                    logger.info(f"æ¨¡å‹å·²ä¸‹è½½åˆ°: {target_path}")
                    return str(target_path)
                else:
                    # å¦‚æœä¸åœ¨ç›®æ ‡ä½ç½®ï¼Œå°è¯•ä» ultralytics ç¼“å­˜ç›®å½•å¤åˆ¶
                    logger.warning("æ¨¡å‹å¯èƒ½ä¸‹è½½åˆ°äº† ultralytics ç¼“å­˜ç›®å½•ï¼Œå°è¯•æŸ¥æ‰¾å¹¶å¤åˆ¶...")
            finally:
                os.chdir(original_cwd)
        except Exception as e:
            logger.warning(f"ç›´æ¥ä¸‹è½½åˆ°ç›®æ ‡ä½ç½®å¤±è´¥: {e}ï¼Œå°è¯•ä»ç¼“å­˜ç›®å½•å¤åˆ¶")
        
        # å¦‚æœç›´æ¥ä¸‹è½½å¤±è´¥ï¼Œå°è¯•ä» ultralytics ç¼“å­˜ç›®å½•å¤åˆ¶
        # ultralytics é»˜è®¤ç¼“å­˜ä½ç½®ï¼š~/.cache/ultralytics/ æˆ– ~/.ultralytics/
        import shutil
        
        # å°è¯•æŸ¥æ‰¾ ultralytics ç¼“å­˜ç›®å½•
        home_dir = Path.home()
        possible_cache_dirs = [
            home_dir / ".cache" / "ultralytics",
            home_dir / ".ultralytics",
            Path.cwd() / ".ultralytics"
        ]
        
        model_name = target_path.name
        for cache_dir in possible_cache_dirs:
            if cache_dir.exists():
                # æŸ¥æ‰¾æ¨¡å‹æ–‡ä»¶ï¼ˆå¯èƒ½åœ¨ weights å­ç›®å½•ä¸­ï¼‰
                possible_locations = [
                    cache_dir / model_name,
                    cache_dir / "weights" / model_name,
                    cache_dir / "hub" / model_name
                ]
                for cached_file in possible_locations:
                    if cached_file.exists():
                        logger.info(f"ä»ç¼“å­˜ç›®å½•å¤åˆ¶æ¨¡å‹: {cached_file} -> {target_path}")
                        shutil.copy2(cached_file, target_path)
                        if target_path.exists():
                            return str(target_path)
        
        # å¦‚æœéƒ½å¤±è´¥äº†ï¼Œè®© ultralytics æ­£å¸¸ä¸‹è½½ï¼ˆä¼šä¸‹è½½åˆ°ç¼“å­˜ç›®å½•ï¼‰
        logger.warning(f"æ— æ³•ç¡®ä¿æ¨¡å‹åœ¨é¡¹ç›®ç›®å½•ï¼Œå°†ä½¿ç”¨ ultralytics é»˜è®¤è¡Œä¸º")
        logger.warning(f"æ¨¡å‹å¯èƒ½ä¼šä¸‹è½½åˆ°: ~/.cache/ultralytics/ æˆ– ~/.ultralytics/")
        return self.model_path
    
    def _load_pytorch_model(self):
        """åŠ è½½ PyTorch æ¨¡å‹"""
        if not ULTRALYTICS_AVAILABLE:
            raise ImportError("ultralytics æœªå®‰è£…ï¼Œæ— æ³•ä½¿ç”¨ PyTorch æ¨¡å¼")
        
        # ç¡®ä¿æ¨¡å‹æ–‡ä»¶åœ¨æ­£ç¡®çš„ä½ç½®ï¼ˆserver/models ç›®å½•ï¼‰
        target_model_path = self._ensure_model_in_project_dir()
        
        self.model = YOLO(target_model_path)
        # å®‰å…¨è·å–ç±»åˆ«åç§°ï¼Œå…¼å®¹ä¸åŒç‰ˆæœ¬çš„ ultralytics
        try:
            names = self.model.names if hasattr(self.model, 'names') else getattr(self.model.model, 'names', None)
            if names is None:
                # å¦‚æœæ— æ³•è·å–ï¼Œä½¿ç”¨é»˜è®¤ COCO ç±»åˆ«
                logger.warning("æ— æ³•ä»æ¨¡å‹è·å–ç±»åˆ«åç§°ï¼Œä½¿ç”¨é»˜è®¤ COCO ç±»åˆ«")
                self.class_names = self._get_default_coco_names()
            elif isinstance(names, dict):
                self.class_names = {int(k): str(v) for k, v in names.items()}
            elif isinstance(names, (list, tuple)):
                self.class_names = {i: str(name) for i, name in enumerate(names)}
            else:
                logger.warning(f"æœªçŸ¥çš„ç±»åˆ«åç§°æ ¼å¼: {type(names)}ï¼Œä½¿ç”¨é»˜è®¤ COCO ç±»åˆ«")
                self.class_names = self._get_default_coco_names()
        except Exception as e:
            logger.warning(f"è·å–ç±»åˆ«åç§°å¤±è´¥: {e}ï¼Œä½¿ç”¨é»˜è®¤ COCO ç±»åˆ«")
            self.class_names = self._get_default_coco_names()
        
        # è®°å½•æ¨¡å‹æ¥æº
        if os.path.exists(target_model_path):
            self.model_source = f"æœ¬åœ°æ–‡ä»¶: {target_model_path}"
        else:
            self.model_source = f"ä» ultralytics ä¸‹è½½: {target_model_path}"
        
        # æ£€æŸ¥æ˜¯å¦ä½¿ç”¨ CUDA
        if TORCH_AVAILABLE and torch.cuda.is_available():
            self.execution_provider = "CUDA"
        else:
            self.execution_provider = "CPU"
    
    def _export_to_onnx(self, onnx_path: str):
        """å¯¼å‡º ONNX æ¨¡å‹"""
        try:
            model = YOLO(self.model_path)
            model.export(
                format="onnx",
                dynamic=True,
                simplify=True,
                opset=12,
                half=False  # ç¦ç”¨ FP16ï¼Œé¿å…ä¸ dynamic å‚æ•°å†²çª
            )
            # ultralytics ä¼šè‡ªåŠ¨ç”Ÿæˆ onnx æ–‡ä»¶ï¼Œé‡å‘½å
            exported_path = self.model_path.replace('.pt', '.onnx')
            if os.path.exists(exported_path) and exported_path != onnx_path:
                os.rename(exported_path, onnx_path)
        except ModuleNotFoundError as e:
            # æ£€æŸ¥æ˜¯å¦æ˜¯ç¼ºå°‘ä¾èµ–æ¨¡å—çš„é”™è¯¯
            error_msg = str(e)
            if 'onnxscript' in error_msg.lower():
                logger.error(f"å¯¼å‡º ONNX æ¨¡å‹å¤±è´¥: ç¼ºå°‘ onnxscript æ¨¡å—")
                raise RuntimeError(
                    f"æ— æ³•å¯¼å‡º ONNX æ¨¡å‹ï¼šç¼ºå°‘å¿…éœ€çš„ä¾èµ–æ¨¡å— 'onnxscript'ã€‚\n"
                    f"è§£å†³æ–¹æ¡ˆï¼š\n"
                    f"1. å®‰è£… onnxscript: pip install onnxscript\n"
                    f"2. æˆ–è€…é‡æ–°å®‰è£… ultralytics åŠå…¶ä¾èµ–: pip install --upgrade ultralytics\n"
                    f"3. æˆ–è€…æ‰‹åŠ¨æä¾› ONNX æ¨¡å‹æ–‡ä»¶: {onnx_path}\n"
                    f"4. æˆ–è€…ä½¿ç”¨ PyTorch æ¨¡å¼ï¼ˆè®¾ç½® use_onnx=Falseï¼‰"
                ) from e
            else:
                logger.error(f"å¯¼å‡º ONNX æ¨¡å‹å¤±è´¥: ç¼ºå°‘ä¾èµ–æ¨¡å— {e}")
                raise RuntimeError(
                    f"æ— æ³•å¯¼å‡º ONNX æ¨¡å‹ï¼šç¼ºå°‘å¿…éœ€çš„ä¾èµ–æ¨¡å—ã€‚\n"
                    f"é”™è¯¯è¯¦æƒ…: {e}\n"
                    f"è§£å†³æ–¹æ¡ˆï¼š\n"
                    f"1. å®‰è£…ç¼ºå¤±çš„ä¾èµ–æ¨¡å—\n"
                    f"2. æˆ–è€…é‡æ–°å®‰è£… ultralytics åŠå…¶ä¾èµ–: pip install --upgrade ultralytics\n"
                    f"3. æˆ–è€…æ‰‹åŠ¨æä¾› ONNX æ¨¡å‹æ–‡ä»¶: {onnx_path}\n"
                    f"4. æˆ–è€…ä½¿ç”¨ PyTorch æ¨¡å¼ï¼ˆè®¾ç½® use_onnx=Falseï¼‰"
                ) from e
        except Exception as e:
            logger.error(f"å¯¼å‡º ONNX æ¨¡å‹å¤±è´¥: {e}")
            # æ£€æŸ¥é”™è¯¯ä¿¡æ¯ä¸­æ˜¯å¦åŒ…å« onnxscript
            error_msg = str(e).lower()
            if 'onnxscript' in error_msg:
                raise RuntimeError(
                    f"æ— æ³•å¯¼å‡º ONNX æ¨¡å‹ï¼šç¼ºå°‘å¿…éœ€çš„ä¾èµ–æ¨¡å— 'onnxscript'ã€‚\n"
                    f"è§£å†³æ–¹æ¡ˆï¼š\n"
                    f"1. å®‰è£… onnxscript: pip install onnxscript\n"
                    f"2. æˆ–è€…é‡æ–°å®‰è£… ultralytics åŠå…¶ä¾èµ–: pip install --upgrade ultralytics\n"
                    f"3. æˆ–è€…æ‰‹åŠ¨æä¾› ONNX æ¨¡å‹æ–‡ä»¶: {onnx_path}\n"
                    f"4. æˆ–è€…ä½¿ç”¨ PyTorch æ¨¡å¼ï¼ˆè®¾ç½® use_onnx=Falseï¼‰"
                ) from e
            else:
                raise RuntimeError(
                    f"æ— æ³•å¯¼å‡º ONNX æ¨¡å‹ã€‚è¯·ç¡®ä¿ï¼š\n"
                    f"1. ultralytics åº“å·²æ­£ç¡®å®‰è£…ä¸”ç‰ˆæœ¬å…¼å®¹\n"
                    f"2. PyTorch æ¨¡å‹æ–‡ä»¶ {self.model_path} å­˜åœ¨ä¸”å¯è®¿é—®\n"
                    f"3. æ‰€æœ‰å¿…éœ€çš„ä¾èµ–æ¨¡å—å·²å®‰è£…ï¼ˆåŒ…æ‹¬ onnxscriptï¼‰\n"
                    f"4. æˆ–è€…æ‰‹åŠ¨æä¾› ONNX æ¨¡å‹æ–‡ä»¶: {onnx_path}\n"
                    f"5. æˆ–è€…ä½¿ç”¨ PyTorch æ¨¡å¼ï¼ˆè®¾ç½® use_onnx=Falseï¼‰"
                ) from e
    
    def _load_class_mapping(self):
        """åŠ è½½ä¸­è‹±æ–‡å¯¹ç…§é…ç½®æ–‡ä»¶"""
        try:
            # ç¡®å®šé…ç½®æ–‡ä»¶è·¯å¾„
            if self.class_mapping_file:
                mapping_path = Path(self.class_mapping_file)
            else:
                # é»˜è®¤è·¯å¾„ï¼šserver/config/coco_classes_zh_en.yaml
                # é€šè¿‡å‘ä¸ŠæŸ¥æ‰¾ config ç›®å½•ï¼Œé¿å…è·¯å¾„å±‚çº§è¯¯åˆ¤
                current_file = Path(__file__).resolve()
                mapping_path = None
                for parent in current_file.parents:
                    candidate = parent / "config" / "coco_classes_zh_en.yaml"
                    if candidate.exists():
                        mapping_path = candidate
                        break
                    # é‡åˆ°é¡¹ç›®æ ¹æ ‡å¿—ï¼ˆåŒ…å« app å’Œ requirements.txtï¼‰å³åœæ­¢
                    if (parent / "app").exists() and (parent / "requirements.txt").exists():
                        mapping_path = candidate
                        break
                if mapping_path is None:
                    # æœ€åå…œåº•ï¼šæŒ‰é¢„æœŸå±‚çº§æ‹¼æ¥
                    mapping_path = current_file.parent.parent.parent.parent / "config" / "coco_classes_zh_en.yaml"
            
            if mapping_path.exists():
                with open(mapping_path, 'r', encoding='utf-8') as f:
                    config = yaml.safe_load(f)
                    self.class_mapping = config.get('mapping', {})
                    self.mapping_defaults = config.get('defaults', {})
                logger.info(f"æˆåŠŸåŠ è½½ä¸­è‹±æ–‡å¯¹ç…§é…ç½®: {mapping_path}ï¼Œå…± {len(self.class_mapping)} ä¸ªæ˜ å°„")
            else:
                logger.warning(f"ä¸­è‹±æ–‡å¯¹ç…§é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {mapping_path}ï¼Œå°†åªä½¿ç”¨è‹±æ–‡åç§°")
                self.class_mapping = {}
                self.mapping_defaults = {}
        except Exception as e:
            logger.warning(f"åŠ è½½ä¸­è‹±æ–‡å¯¹ç…§é…ç½®å¤±è´¥: {e}ï¼Œå°†åªä½¿ç”¨è‹±æ–‡åç§°")
            self.class_mapping = {}
            self.mapping_defaults = {}
    
    def _translate_class_name(self, english_name: str) -> str:
        """
        å°†è‹±æ–‡ç±»åˆ«åç§°ç¿»è¯‘ä¸ºä¸­æ–‡
        
        Args:
            english_name: è‹±æ–‡ç±»åˆ«åç§°
            
        Returns:
            ä¸­æ–‡ç±»åˆ«åç§°ï¼Œå¦‚æœæ‰¾ä¸åˆ°æ˜ å°„åˆ™è¿”å›è‹±æ–‡åç§°
        """
        if not self.use_chinese:
            return english_name
        
        chinese_name = self.class_mapping.get(english_name)
        if chinese_name:
            return chinese_name
        
        # å¦‚æœæ‰¾ä¸åˆ°æ˜ å°„ï¼Œä½¿ç”¨é»˜è®¤æ ¼å¼
        fallback_format = self.mapping_defaults.get('fallback_format', '{en}')
        return fallback_format.format(en=english_name, zh=self.mapping_defaults.get('unknown_zh', 'æœªçŸ¥'))
    
    def _get_default_coco_names(self) -> Dict[int, str]:
        """
        è·å– COCO ç±»åˆ«åç§°çš„å”¯ä¸€æ•°æ®æºã€‚
        
        - ä¼˜å…ˆä½¿ç”¨é…ç½®æ–‡ä»¶çš„è‹±æ–‡åç§°ï¼ˆclass_mapping çš„é”®ï¼‰
        - è‹¥æœªåŠ è½½åˆ°é…ç½®ï¼ˆæˆ–ç¼ºå¤±ï¼‰ï¼Œç›´æ¥æŠ›å‡ºé”™è¯¯ï¼Œæç¤ºç”¨æˆ·æä¾›æ˜ å°„
        
        ä¿æŒæ¨¡å—èŒè´£æ¸…æ™°ï¼šä¸å†ç”¨ç¡¬ç¼–ç åˆ—è¡¨å…œåº•ã€‚
        """
        if self.class_mapping:
            english_names = list(self.class_mapping.keys())
            return {i: name for i, name in enumerate(english_names)}
        
        mapping_hint = self.class_mapping_file or "server/config/coco_classes_zh_en.yaml"
        raise RuntimeError(
            f"æœªæ‰¾åˆ°ç±»åˆ«æ˜ å°„ï¼Œè¯·æä¾›ä¸­è‹±æ–‡æ˜ å°„é…ç½®æ–‡ä»¶: {mapping_hint}"
        )
    
    def _preprocess_image(self, image_data: bytes) -> np.ndarray:
        """å›¾åƒé¢„å¤„ç†"""
        nparr = np.frombuffer(image_data, np.uint8)
        image = cv2.imdecode(nparr, cv2.IMREAD_COLOR)
        if image is None:
            raise ValueError("æ— æ³•è§£ç å›¾åƒæ•°æ®ã€‚è¯·ç¡®ä¿è¾“å…¥æ˜¯æœ‰æ•ˆçš„ JPEGã€PNG æˆ–å…¶ä»– OpenCV æ”¯æŒçš„å›¾åƒæ ¼å¼")
        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        return image
    
    def _prepare_onnx_input(self, image: np.ndarray) -> np.ndarray:
        """å‡†å¤‡ ONNX è¾“å…¥"""
        # YOLOv8 è¾“å…¥å°ºå¯¸é€šå¸¸æ˜¯ 640x640
        input_size = 640
        h, w = image.shape[:2]
        
        # ç¼©æ”¾å¹¶å¡«å……
        scale = min(input_size / h, input_size / w)
        new_h, new_w = int(h * scale), int(w * scale)
        
        resized = cv2.resize(image, (new_w, new_h), interpolation=cv2.INTER_LINEAR)
        
        # åˆ›å»ºå¡«å……å›¾åƒ
        padded = np.full((input_size, input_size, 3), 114, dtype=np.uint8)
        padded[:new_h, :new_w] = resized
        
        # è½¬æ¢ä¸ºæ¨¡å‹è¾“å…¥æ ¼å¼ [1, 3, 640, 640]ï¼Œå½’ä¸€åŒ–åˆ° [0, 1]
        input_tensor = padded.transpose(2, 0, 1).astype(np.float32) / 255.0
        input_tensor = np.expand_dims(input_tensor, axis=0)
        
        return input_tensor
    
    def _postprocess_onnx(
        self, 
        outputs: List[np.ndarray], 
        image_shape: tuple
    ) -> List[Dict[str, Any]]:
        """ONNX è¾“å‡ºåå¤„ç†"""
        # YOLOv8 ONNX è¾“å‡ºæ ¼å¼é€šå¸¸æ˜¯: [batch, 84, num_detections]
        # å…¶ä¸­ 84 = 4 (bbox: x_center, y_center, width, height) + 80 (classes)
        # num_detections é€šå¸¸æ˜¯ 8400 (80*80 + 40*40 + 20*20 = 6400 + 1600 + 400)
        
        output = outputs[0]  # è·å–ç¬¬ä¸€ä¸ªè¾“å‡º [batch, 84, num_detections]
        
        # è°ƒè¯•ï¼šè¾“å‡ºå½¢çŠ¶ä¿¡æ¯
        logger.debug(f"ONNX è¾“å‡ºåŸå§‹å½¢çŠ¶: {output.shape}")
        
        # ç§»é™¤ batch ç»´åº¦
        if len(output.shape) == 3:
            output = output[0]  # [84, num_detections]
        
        # YOLOv8 è¾“å‡ºæ ¼å¼æ˜¯ [84, num_detections]ï¼Œéœ€è¦è½¬ç½®ä¸º [num_detections, 84]
        if output.shape[0] == 84:
            output = output.T  # è½¬ç½®ä¸º [num_detections, 84]
            logger.debug(f"è½¬ç½®åå½¢çŠ¶: {output.shape}")
        elif output.shape[1] != 84:
            logger.warning(f"æ„å¤–çš„è¾“å‡ºå½¢çŠ¶: {output.shape}ï¼ŒæœŸæœ›ç¬¬äºŒä¸ªç»´åº¦ä¸º 84")
            return []
        
        detections = []
        h, w = image_shape[:2]
        
        # ç¡®ä¿ class_names æ˜¯å­—å…¸æ ¼å¼ï¼Œä¸”é”®æ˜¯æ•´æ•°
        if not isinstance(self.class_names, dict):
            # å¦‚æœæ˜¯åˆ—è¡¨æˆ–å…¶ä»–æ ¼å¼ï¼Œè½¬æ¢ä¸ºå­—å…¸
            if isinstance(self.class_names, (list, tuple)):
                self.class_names = {i: str(name) for i, name in enumerate(self.class_names)}
            else:
                logger.warning(f"class_names æ ¼å¼ä¸æ­£ç¡®: {type(self.class_names)}ï¼Œä½¿ç”¨é»˜è®¤ COCO ç±»åˆ«")
                self.class_names = self._get_default_coco_names()
        
        # ç¡®ä¿æ‰€æœ‰é”®éƒ½æ˜¯æ•´æ•°
        self.class_names = {int(k): str(v) for k, v in self.class_names.items()}
        
        for detection in output:
            # æ£€æŸ¥ detection çš„é•¿åº¦
            if len(detection) < 84:
                logger.warning(f"æ£€æµ‹ç»“æœé•¿åº¦ä¸è¶³: {len(detection)}ï¼ŒæœŸæœ› 84ï¼Œè·³è¿‡")
                continue
            
            # æå–è¾¹ç•Œæ¡†å’Œç±»åˆ«åˆ†æ•°
            bbox = detection[:4]  # [x_center, y_center, width, height] (å½’ä¸€åŒ–)
            scores = detection[4:84]  # 80ä¸ªç±»åˆ«çš„åˆ†æ•°ï¼ˆç´¢å¼• 4-83ï¼‰
            
            # æ‰¾åˆ°æœ€é«˜åˆ†æ•°å’Œå¯¹åº”ç±»åˆ«
            class_id = int(np.argmax(scores))
            confidence = float(scores[class_id])
            
            # è¿‡æ»¤ä½ç½®ä¿¡åº¦æ£€æµ‹
            if confidence < self.confidence_threshold:
                continue
            
            # ç¡®ä¿ class_id åœ¨æœ‰æ•ˆèŒƒå›´å†…ï¼ˆCOCO æ•°æ®é›†æ˜¯ 0-79ï¼‰
            if class_id >= 80:
                logger.warning(f"æ£€æµ‹åˆ°æ— æ•ˆçš„ç±»åˆ« ID: {class_id}ï¼ˆè¶…å‡º COCO 80 ç±»èŒƒå›´ï¼‰ï¼Œè·³è¿‡æ­¤æ£€æµ‹")
                continue
            
            # è·å–ç±»åˆ«åç§°ï¼ˆè‹±æ–‡ï¼‰
            class_name_en = self.class_names.get(class_id)
            if class_name_en is None:
                # ä½¿ç”¨é»˜è®¤ COCO ç±»åˆ«åç§°
                default_names = self._get_default_coco_names()
                class_name_en = default_names.get(class_id)
                if class_name_en is None:
                    logger.warning(f"æœªæ‰¾åˆ°ç±»åˆ« ID {class_id} çš„åç§°ï¼Œä½¿ç”¨é»˜è®¤åç§°")
                    class_name_en = f"ç‰©ä½“_{class_id}"
                else:
                    logger.debug(f"ä»é»˜è®¤ç±»åˆ«åç§°è·å–: {class_id} -> {class_name_en}")
            
            # ç¿»è¯‘ä¸ºä¸­æ–‡ï¼ˆå¦‚æœéœ€è¦ï¼‰
            class_name = self._translate_class_name(class_name_en)
            
            # è½¬æ¢è¾¹ç•Œæ¡†æ ¼å¼ [x1, y1, x2, y2] (åƒç´ åæ ‡)
            x_center, y_center, width, height = bbox
            x1 = (x_center - width / 2) * w
            y1 = (y_center - height / 2) * h
            x2 = (x_center + width / 2) * w
            y2 = (y_center + height / 2) * h
            
            detections.append({
                "class": class_name,
                "class_en": class_name_en,  # ä¿ç•™è‹±æ–‡åç§°
                "class_id": class_id,
                "confidence": confidence,
                "bbox": [float(x1), float(y1), float(x2), float(y2)]
            })
        
        # NMS (ç®€åŒ–ç‰ˆï¼Œä½¿ç”¨ç½®ä¿¡åº¦æ’åº)
        detections.sort(key=lambda x: x["confidence"], reverse=True)
        filtered_detections = []
        for det in detections:
            # ç®€å•çš„ IOU è¿‡æ»¤
            overlap = False
            for existing in filtered_detections:
                iou = self._calculate_iou(det["bbox"], existing["bbox"])
                if iou > self.iou_threshold:
                    overlap = True
                    break
            if not overlap:
                filtered_detections.append(det)
        
        return filtered_detections
    
    def _calculate_iou(self, box1: List[float], box2: List[float]) -> float:
        """è®¡ç®—ä¸¤ä¸ªè¾¹ç•Œæ¡†çš„ IOU"""
        x1_1, y1_1, x2_1, y2_1 = box1
        x1_2, y1_2, x2_2, y2_2 = box2
        
        # è®¡ç®—äº¤é›†
        x1_i = max(x1_1, x1_2)
        y1_i = max(y1_1, y1_2)
        x2_i = min(x2_1, x2_2)
        y2_i = min(y2_1, y2_2)
        
        if x2_i <= x1_i or y2_i <= y1_i:
            return 0.0
        
        intersection = (x2_i - x1_i) * (y2_i - y1_i)
        area1 = (x2_1 - x1_1) * (y2_1 - y1_1)
        area2 = (x2_2 - x1_2) * (y2_2 - y1_2)
        union = area1 + area2 - intersection
        
        return intersection / union if union > 0 else 0.0
    
    def _predict_onnx(self, image: np.ndarray) -> List[Dict[str, Any]]:
        """ONNX æ¨ç†"""
        input_tensor = self._prepare_onnx_input(image)
        
        # æ¨ç†
        outputs = self.ort_session.run(self.output_names, {self.input_name: input_tensor})
        
        # åå¤„ç†
        return self._postprocess_onnx(outputs, image.shape)
    
    def _predict_pytorch(self, image: np.ndarray) -> List[Dict[str, Any]]:
        """PyTorch æ¨ç†"""
        # ultralytics YOLO æ¨¡å‹å¯ä»¥ç›´æ¥æ¥å— numpy æ•°ç»„
        # ä½†éœ€è¦ç¡®ä¿æ ¼å¼æ­£ç¡®ï¼šBGR æ ¼å¼ï¼Œuint8 ç±»å‹
        # æ³¨æ„ï¼š_preprocess_image è¿”å›çš„æ˜¯ RGB æ ¼å¼ï¼Œéœ€è¦è½¬æ¢ä¸º BGR
        if image.dtype != np.uint8:
            image = (image * 255).astype(np.uint8) if image.max() <= 1.0 else image.astype(np.uint8)
        
        # å°† RGB è½¬æ¢ä¸º BGRï¼ˆultralytics æœŸæœ› BGR æ ¼å¼ï¼‰
        if len(image.shape) == 3 and image.shape[2] == 3:
            image_bgr = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)
        else:
            image_bgr = image
        
        # ç›´æ¥ä¼ é€’ numpy æ•°ç»„ç»™æ¨¡å‹
        # ultralytics 8.0.0+ æ”¯æŒç›´æ¥ä¼ é€’ numpy æ•°ç»„
        # ä½¿ç”¨ source å‚æ•°æ˜ç¡®æŒ‡å®šï¼Œé¿å…å†…éƒ¨è·¯å¾„æ£€æŸ¥
        try:
            results = self.model.predict(
                source=image_bgr,
                conf=self.confidence_threshold,
                iou=self.iou_threshold,
                verbose=False
            )
        except (ValueError, FileNotFoundError, TypeError) as e:
            # å¦‚æœç›´æ¥ä¼ é€’å¤±è´¥ï¼Œå°è¯•ä½¿ç”¨ä¸´æ—¶æ–‡ä»¶ï¼ˆæœ€åçš„æ‰‹æ®µï¼‰
            logger.warning(f"ç›´æ¥ä¼ é€’ numpy æ•°ç»„å¤±è´¥: {e}ï¼Œå°è¯•ä½¿ç”¨ä¸´æ—¶æ–‡ä»¶")
            import tempfile
            with tempfile.NamedTemporaryFile(suffix='.jpg', delete=False) as tmp_file:
                cv2.imwrite(tmp_file.name, image_bgr)
                try:
                    results = self.model.predict(
                        source=tmp_file.name,
                        conf=self.confidence_threshold,
                        iou=self.iou_threshold,
                        verbose=False
                    )
                finally:
                    # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                    try:
                        os.unlink(tmp_file.name)
                    except:
                        pass
        detections = []
        
        # ç¡®ä¿ results æ˜¯åˆ—è¡¨
        if not isinstance(results, list):
            results = [results]
        
        for result in results:
            # æ£€æŸ¥ result æ˜¯å¦æ˜¯ Results å¯¹è±¡ï¼ˆæœ‰ boxes å±æ€§ï¼‰
            if hasattr(result, 'boxes'):
                # æ­£å¸¸çš„ Results å¯¹è±¡å¤„ç†
                boxes = result.boxes
                if boxes is not None and len(boxes) > 0:
                    for box in boxes:
                        class_id = int(box.cls)
                        class_name_en = self.class_names.get(class_id)
                        if class_name_en is None:
                            # å¦‚æœæ‰¾ä¸åˆ°ï¼Œå°è¯•ä»é»˜è®¤åç§°è·å–
                            default_names = self._get_default_coco_names()
                            class_name_en = default_names.get(class_id, f"ç‰©ä½“_{class_id}")
                        
                        # ç¿»è¯‘ä¸ºä¸­æ–‡ï¼ˆå¦‚æœéœ€è¦ï¼‰
                        class_name = self._translate_class_name(class_name_en)
                        
                        detections.append({
                            "class": class_name,
                            "class_en": class_name_en,  # ä¿ç•™è‹±æ–‡åç§°
                            "class_id": class_id,
                            "confidence": float(box.conf),
                            "bbox": box.xyxy[0].tolist()  # [x1, y1, x2, y2]
                        })
            else:
                # å¤„ç†è¿”å› Tensor çš„æƒ…å†µï¼ˆæŸäº› ultralytics ç‰ˆæœ¬æˆ–é…ç½®ä¸‹å¯èƒ½å‘ç”Ÿï¼‰
                if TORCH_AVAILABLE and hasattr(result, 'shape'):
                    # æ£€æŸ¥æ˜¯å¦æ˜¯ PyTorch Tensor
                    if isinstance(result, torch.Tensor) or (hasattr(result, 'shape') and hasattr(result, 'cpu')):
                        logger.debug(f"predict è¿”å›äº† Tensor å¯¹è±¡ï¼Œshape: {result.shape}ï¼Œå°è¯•è§£æ")
                        # Tensor æ ¼å¼é€šå¸¸æ˜¯ [N, 6]ï¼Œå…¶ä¸­ N æ˜¯æ£€æµ‹æ¡†æ•°é‡ï¼Œ6 æ˜¯ [x1, y1, x2, y2, conf, cls]
                        if len(result.shape) == 2 and result.shape[1] == 6:
                            # è½¬æ¢ä¸º numpy æ•°ç»„è¿›è¡Œå¤„ç†
                            if hasattr(result, 'cpu'):
                                result_np = result.cpu().numpy()
                            elif hasattr(result, 'numpy'):
                                result_np = result.numpy()
                            else:
                                result_np = np.array(result)
                            
                            # è¿‡æ»¤ç½®ä¿¡åº¦ä½äºé˜ˆå€¼çš„æ£€æµ‹æ¡†
                            for det in result_np:
                                x1, y1, x2, y2, conf, cls_id = det
                                if conf >= self.confidence_threshold:
                                    class_id = int(cls_id)
                                    class_name_en = self.class_names.get(class_id)
                                    if class_name_en is None:
                                        default_names = self._get_default_coco_names()
                                        class_name_en = default_names.get(class_id, f"ç‰©ä½“_{class_id}")
                                    
                                    class_name = self._translate_class_name(class_name_en)
                                    
                                    detections.append({
                                        "class": class_name,
                                        "class_en": class_name_en,
                                        "class_id": class_id,
                                        "confidence": float(conf),
                                        "bbox": [float(x1), float(y1), float(x2), float(y2)]
                                    })
                            
                            # å¦‚æœæ²¡æœ‰æ£€æµ‹åˆ°ç‰©ä½“ï¼ˆshape æ˜¯ [0, 6]ï¼‰ï¼Œè¿™æ˜¯æ­£å¸¸çš„ï¼Œä¸éœ€è¦è®°å½•é”™è¯¯
                            if result.shape[0] == 0:
                                logger.debug("Tensor å½¢çŠ¶ä¸º [0, 6]ï¼Œè¡¨ç¤ºæœªæ£€æµ‹åˆ°ç‰©ä½“ï¼ˆæ­£å¸¸æƒ…å†µï¼‰")
                        else:
                            logger.warning(f"æ— æ³•è§£æ Tensor æ ¼å¼ï¼Œshape: {result.shape}ï¼ŒæœŸæœ› [N, 6]")
                    else:
                        logger.warning(f"predict è¿”å›äº†é Results å¯¹è±¡ä¸”ä¸æ˜¯ Tensor: {type(result)}")
                else:
                    logger.warning(f"predict è¿”å›äº†é Results å¯¹è±¡: {type(result)}ï¼Œä¸” PyTorch ä¸å¯ç”¨ï¼Œæ— æ³•è§£æ")
        
        return detections
    
    async def describe(self, image_bytes: bytes) -> Dict[str, Any]:
        """
        æ‰§è¡Œæ¨ç†é¢„æµ‹
        
        Args:
            image_bytes: å›¾åƒå­—èŠ‚æ•°æ®
            
        Returns:
            åŒ…å«æ£€æµ‹ç»“æœçš„å­—å…¸
        """
        start_time = time.time()
        
        try:
            # é¢„å¤„ç†å›¾åƒ
            image = self._preprocess_image(image_bytes)
            
            # æ‰§è¡Œæ¨ç†
            if self.use_onnx:
                detections = self._predict_onnx(image)
            else:
                detections = self._predict_pytorch(image)
            
            inference_time = time.time() - start_time
            
            logger.info(f"YOLOv8n æ¨ç†å®Œæˆ: {len(detections)} ä¸ªæ£€æµ‹, è€—æ—¶ {inference_time:.3f}s")
            
            return {
                "detections": detections,
                "inference_time": inference_time,
                "model": "yolov8n",
                "timestamp": time.time(),
                "image_shape": image.shape[:2]
            }
            
        except Exception as e:
            logger.error(f"æ¨ç†å¤±è´¥: {e}", exc_info=True)
            raise
    
    def _print_model_info(self):
        """æ‰“å°æ¨¡å‹è¯¦ç»†ä¿¡æ¯"""
        print("\n" + "-" * 60)
        print("ğŸ“¦ YOLOv8n è§†è§‰æ¨¡å‹ä¿¡æ¯")
        print("-" * 60)
        print(f"   æ¨¡å‹ç±»å‹: {'ONNX' if self.use_onnx else 'PyTorch'}")
        print(f"   æ‰§è¡Œè®¾å¤‡: {self.execution_provider or 'æœªçŸ¥'}")
        print(f"   æ¨¡å‹æ¥æº: {self.model_source or 'æœªçŸ¥'}")
        print(f"   æ¨¡å‹çŠ¶æ€: {'âœ… å¯ç”¨' if (self.ort_session is not None or self.model is not None) else 'âŒ ä¸å¯ç”¨'}")
        
        if self.class_names:
            print(f"   ç±»åˆ«æ•°é‡: {len(self.class_names)}")
            # æ˜¾ç¤ºå‰5ä¸ªç±»åˆ«ä½œä¸ºç¤ºä¾‹
            sample_classes = list(self.class_names.values())[:5]
            print(f"   ç¤ºä¾‹ç±»åˆ«: {', '.join(sample_classes)}" + ("..." if len(self.class_names) > 5 else ""))
        
        if self.input_shape:
            print(f"   è¾“å…¥å½¢çŠ¶: {self.input_shape}")
        
        if self.use_onnx and self.ort_session:
            print(f"   è¾“å…¥åç§°: {self.input_name}")
            print(f"   è¾“å‡ºåç§°: {', '.join(self.output_names)}")
        
        print(f"   ç½®ä¿¡åº¦é˜ˆå€¼: {self.confidence_threshold}")
        print(f"   IOU é˜ˆå€¼: {self.iou_threshold}")
        print("-" * 60 + "\n")
    
    def get_model_info(self) -> Dict[str, Any]:
        """è·å–æ¨¡å‹ä¿¡æ¯å­—å…¸"""
        return {
            "model_type": "ONNX" if self.use_onnx else "PyTorch",
            "execution_provider": self.execution_provider or "æœªçŸ¥",
            "model_source": self.model_source or "æœªçŸ¥",
            "status": "å¯ç”¨" if (self.ort_session is not None or self.model is not None) else "ä¸å¯ç”¨",
            "class_count": len(self.class_names) if self.class_names else 0,
            "input_shape": list(self.input_shape) if self.input_shape else None,
            "confidence_threshold": self.confidence_threshold,
            "iou_threshold": self.iou_threshold
        }

