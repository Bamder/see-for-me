// mobile/src/modules/TTSModule/models/PaddleSpeechAdapter.ts
import { BaseTTSModel, TTSModelConfig, TTSResult } from './BaseTTSModel';
// ä½¿ç”¨ legacy API ä»¥é¿å…å¼ƒç”¨è­¦å‘Š
import * as FileSystem from 'expo-file-system/legacy';
import { NativeModules, Platform } from 'react-native';

// åŸç”Ÿæ¨¡å—æ¥å£å®šä¹‰
interface ModelFileCopierModule {
  copyModels(): Promise<boolean>;
}

const { ModelFileCopier } = NativeModules;

// Base64ç¼–ç /è§£ç å·¥å…·å‡½æ•°ï¼ˆä¸ä¾èµ–å¤–éƒ¨åº“ï¼‰
function base64Encode(buffer: ArrayBuffer): string {
  const bytes = new Uint8Array(buffer);
  let binary = '';
  for (let i = 0; i < bytes.byteLength; i++) {
    binary += String.fromCharCode(bytes[i]);
  }
  // ä½¿ç”¨btoaï¼ˆæµè§ˆå™¨ç¯å¢ƒï¼‰æˆ–Bufferï¼ˆNodeç¯å¢ƒï¼‰
  if (typeof btoa !== 'undefined') {
    return btoa(binary);
  } else if (typeof Buffer !== 'undefined') {
    return Buffer.from(binary, 'binary').toString('base64');
  } else {
    // æ‰‹åŠ¨å®ç°Base64ç¼–ç 
    const chars = 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/';
    let result = '';
    let i = 0;
    while (i < binary.length) {
      const a = binary.charCodeAt(i++);
      const b = i < binary.length ? binary.charCodeAt(i++) : 0;
      const c = i < binary.length ? binary.charCodeAt(i++) : 0;
      const bitmap = (a << 16) | (b << 8) | c;
      result += chars.charAt((bitmap >> 18) & 63);
      result += chars.charAt((bitmap >> 12) & 63);
      result += i - 2 < binary.length ? chars.charAt((bitmap >> 6) & 63) : '=';
      result += i - 1 < binary.length ? chars.charAt(bitmap & 63) : '=';
    }
    return result;
  }
}

/**
 * PaddleSpeech Liteé€‚é…å™¨
 * ä½¿ç”¨ONNX Runtimeåœ¨ç§»åŠ¨ç«¯è¿è¡ŒPaddleSpeechæ¨¡å‹
 */
export class PaddleSpeechAdapter extends BaseTTSModel {
  public readonly name = 'PaddleSpeech-Lite-Chinese';
  public readonly version = '2.5.0';
  public readonly supportedLanguages = ['zh-CN'];
  
  // æ¨¡å‹æ–‡ä»¶åŸºç¡€è·¯å¾„ï¼ˆç»Ÿä¸€ç®¡ç†ï¼Œé¿å…æ‹¼å†™é”™è¯¯ï¼‰
  private static readonly BASE_ASSETS_PATH = '../../../assets/tts-models/paddlespeech-lite';
  
  private ort: any = null;
  private frontendSession: any = null;
  private acousticSession: any = null;
  private vocoderSession: any = null;
  private isInitialized: boolean = false;
  private sampleRate: number = 24000;

  constructor() {
    super({
      language: 'zh-CN',
      sampleRate: 24000,
      speed: 1.0,
      pitch: 1.0
    });
  }

  async loadModel(config: TTSModelConfig): Promise<void> {
    try {
      this.setStatus('loading');
      this.updateConfig(config);
      
      // åªåœ¨æˆåŠŸæ—¶è¾“å‡ºæ—¥å¿—ï¼ˆé¿å…å™ªéŸ³ï¼‰
      if (__DEV__) {
        console.log('ğŸ”Š å°è¯•åŠ è½½PaddleSpeech Liteæ¨¡å‹...');
      }
      
      // åŠ¨æ€å¯¼å…¥ONNX Runtimeï¼ˆå¯é€‰ï¼Œå¦‚æœæœªå®‰è£…ä¼šä½¿ç”¨æ¨¡æ‹Ÿæ¨¡å¼ï¼‰
      this.ort = await this.loadONNXRuntime();
      
      // åŠ è½½æ‰€æœ‰æ¨¡å‹ç»„ä»¶ï¼ˆå³ä½¿ ONNX Runtime ä¸å¯ç”¨ï¼Œä¹Ÿå…ˆå¤åˆ¶æ¨¡å‹æ–‡ä»¶ï¼‰
      // è¿™æ ·å½“ ONNX Runtime å¯ç”¨æ—¶å°±èƒ½ç›´æ¥ä½¿ç”¨
      await this.loadModelComponents();
      
      // å¦‚æœæ²¡æœ‰ ONNX Runtimeï¼Œè¿›å…¥æ¨¡æ‹Ÿæ¨¡å¼
      if (!this.ort) {
        // é™é»˜å¤„ç†ï¼Œä¸è¾“å‡ºæ—¥å¿—ï¼ˆç³»ç»Ÿä¼šè‡ªåŠ¨å›é€€åˆ°ç³»ç»ŸTTSï¼‰
        this.isInitialized = true;
        this.setStatus('loaded');
        return;
      }
      
      this.isInitialized = true;
      this.setStatus('loaded');
      
      // åªåœ¨æˆåŠŸæ—¶è¾“å‡ºæ—¥å¿—
      if (__DEV__) {
        console.log('âœ… PaddleSpeech Liteæ¨¡å‹åŠ è½½å®Œæˆ');
      }
      
    } catch (error) {
      this.setStatus('error');
      console.error('åŠ è½½PaddleSpeechæ¨¡å‹å¤±è´¥:', error);
      throw new Error(`PaddleSpeechæ¨¡å‹åŠ è½½å¤±è´¥: ${error instanceof Error ? error.message : 'æœªçŸ¥é”™è¯¯'}`);
    }
  }

  private async loadONNXRuntime(): Promise<any> {
    // å…³é”®ï¼šåœ¨ require ä¹‹å‰å…ˆæ£€æµ‹ç¯å¢ƒï¼Œé¿å…æ¨¡å—åŠ è½½æ—¶è®¿é—®åŸç”Ÿæ¨¡å—å¯¼è‡´é”™è¯¯
    
    // æ–¹æ³•1: æ£€æµ‹ Expo Go ç¯å¢ƒ
    try {
      const Constants = await import('expo-constants').catch(() => null);
      if (Constants?.default?.executionEnvironment === 'storeClient') {
        // é™é»˜å¤„ç†ï¼Œä¸è¾“å‡ºæ—¥å¿—
        return null;
      }
    } catch {
      // ç»§ç»­æ£€æµ‹
    }
    
    // æ–¹æ³•2: æ£€æŸ¥æ˜¯å¦åœ¨åŸç”Ÿæ„å»ºç¯å¢ƒä¸­
    // å¦‚æœæ˜¯åœ¨å¼€å‘ç¯å¢ƒä¸­ä¸”æ²¡æœ‰åŸç”Ÿæ„å»ºï¼Œç›´æ¥è¿”å› null
    try {
      // å°è¯•æ£€æŸ¥åŸç”Ÿæ¨¡å—æ˜¯å¦å¯ç”¨ï¼ˆç®€å•æ£€æµ‹ï¼‰
      const { NativeModules } = require('react-native');
      // å¦‚æœåŸç”Ÿæ¨¡å—æ•°é‡éå¸¸å°‘ï¼Œå¯èƒ½æ˜¯ Expo Go ç¯å¢ƒ
      const nativeModuleCount = Object.keys(NativeModules || {}).length;
      if (nativeModuleCount < 10) {
        // é™é»˜å¤„ç†ï¼Œä¸è¾“å‡ºæ—¥å¿—ï¼ˆé¿å…æ§åˆ¶å°å™ªéŸ³ï¼‰
        return null;
      }
    } catch {
      // å¦‚æœæ— æ³•æ£€æŸ¥ï¼Œç›´æ¥è¿”å› nullï¼ˆå®‰å…¨èµ·è§ï¼Œé¿å…å°è¯•åŠ è½½ï¼‰
      return null;
    }
    
    // å°è¯•åŠ è½½æ¨¡å—
    // æ³¨æ„ï¼šå³ä½¿æœ‰ try-catchï¼Œæ¨¡å—åŠ è½½æ—¶çš„åŒæ­¥é”™è¯¯å¯èƒ½ä»ç„¶ä¼šæ˜¾ç¤ºåœ¨æ§åˆ¶å°
    // ä½†æˆ‘ä»¬å¯ä»¥æ•è·å®ƒå¹¶è¿”å› nullï¼Œè®©ç³»ç»Ÿä½¿ç”¨å›é€€æ–¹æ¡ˆ
    try {
      if (typeof require === 'undefined') {
        return null;
      }
      
      // å°è¯•åŠ è½½æ¨¡å—
      // è­¦å‘Šï¼šå³ä½¿æœ‰ try-catchï¼ŒåŸç”Ÿæ¨¡å—çš„é”™è¯¯å¯èƒ½åœ¨æ§åˆ¶å°æ˜¾ç¤º
      // è¿™æ˜¯æ­£å¸¸çš„ï¼Œå› ä¸ºæˆ‘ä»¬ä¼šåœ¨ catch ä¸­å¤„ç†å¹¶è¿”å› nullï¼Œä½¿ç”¨ç³»ç»ŸTTSå›é€€
      const ortModule = require('onnxruntime-react-native');
      
      // æ£€æŸ¥æ¨¡å—ç»“æ„
      if (!ortModule || typeof ortModule !== 'object') {
        return null;
      }
      
      // æ£€æŸ¥å…³é”® API
      const ort = ortModule.default || ortModule;
      if (!ort || typeof ort !== 'object' || !ort.InferenceSession || typeof ort.InferenceSession.create !== 'function') {
        return null;
      }
      
      // åªåœ¨æˆåŠŸæ—¶è¾“å‡ºæ—¥å¿—
      if (__DEV__) {
        console.log('âœ… ONNX Runtime RN åŠ è½½æˆåŠŸ');
      }
      return ort;
      
    } catch (error: any) {
      // æ•è· require å’Œæ¨¡å—åˆå§‹åŒ–æ—¶çš„æ‰€æœ‰é”™è¯¯
      // æ³¨æ„ï¼šå³ä½¿æ•è·äº†é”™è¯¯ï¼ŒåŸç”Ÿæ¨¡å—çš„é”™è¯¯ä»ç„¶å¯èƒ½æ˜¾ç¤ºåœ¨æ§åˆ¶å°
      // ä½†ä¸ä¼šå½±å“ç¨‹åºè¿è¡Œï¼Œå› ä¸ºæˆ‘ä»¬è¿”å› null è®©ç³»ç»Ÿä½¿ç”¨å›é€€æ–¹æ¡ˆ
      
      const errorMessage = error?.message || String(error);
      const errorStack = error?.stack || '';
      
      // åˆ¤æ–­æ˜¯å¦æ˜¯åŸç”Ÿæ¨¡å—ç›¸å…³é”™è¯¯
      const isNativeModuleError = 
        errorMessage.includes('Cannot read property') ||
        errorMessage.includes('install') ||
        errorMessage.includes('null') ||
        errorMessage.includes('undefined') ||
        errorMessage.includes('Native module') ||
        errorMessage.includes('MODULE_NOT_FOUND') ||
        errorStack.includes('binding.ts') ||
        errorStack.includes('onnxruntime-react-native') ||
        errorStack.includes('backend.ts');
      
      if (isNativeModuleError) {
        // é™é»˜å¤„ç†ï¼Œä¸è¾“å‡ºè­¦å‘Šï¼ˆå› ä¸ºè¿™æ˜¯é¢„æœŸçš„ï¼‰
        // åªåœ¨è°ƒè¯•æ—¶è¾“å‡º
        if (__DEV__) {
          console.log('â„¹ï¸ ONNX Runtime RN ä¸å¯ç”¨ï¼ˆéœ€è¦åŸç”Ÿæ„å»ºï¼‰ï¼Œå°†ä½¿ç”¨ç³»ç»ŸTTS');
        }
      }
      
      // é™é»˜è¿”å› nullï¼Œè®©ç³»ç»Ÿä½¿ç”¨å›é€€æ–¹æ¡ˆï¼ˆç³»ç»ŸTTSï¼‰
      return null;
    }
  }

  private async fallbackONNXRuntime(): Promise<any> {
    // é€šè¿‡WebViewè¿è¡ŒONNX Runtime Web
    // è¿™æ˜¯ä¸€ä¸ªå¤‡é€‰æ–¹æ¡ˆï¼Œæ€§èƒ½è¾ƒå·®ä½†å…¼å®¹æ€§å¥½
    console.log('ä½¿ç”¨WebView ONNX Runtimeåå¤‡æ–¹æ¡ˆ');
    return {
      InferenceSession: {
        create: async () => ({ 
          run: () => Promise.resolve({}) 
        })
      }
    };
  }

  private async loadModelComponents(): Promise<void> {
    // å³ä½¿ ONNX Runtime ä¸å¯ç”¨ï¼Œä¹Ÿå…ˆå°è¯•å¤åˆ¶æ¨¡å‹æ–‡ä»¶
    // è¿™æ ·å½“ ONNX Runtime å¯ç”¨æ—¶å°±èƒ½ç›´æ¥ä½¿ç”¨
    const modelAssets = await this.loadModelAssets();
    
    // å¦‚æœæ²¡æœ‰ ONNX Runtimeï¼Œæ— æ³•åŠ è½½æ¨¡å‹ï¼Œç›´æ¥è¿”å›æ¨¡æ‹Ÿæ¨¡å¼
    if (!this.ort) {
      console.log('â„¹ï¸ ONNX Runtimeä¸å¯ç”¨ï¼Œè·³è¿‡æ¨¡å‹åŠ è½½ï¼Œä½¿ç”¨æ¨¡æ‹Ÿæ¨¡å¼');
      this.isInitialized = true;
      this.setStatus('loaded');
      return;
    }
    
    // æ£€æŸ¥å¿…éœ€çš„æ¨¡å‹æ–‡ä»¶ï¼ˆå£°å­¦æ¨¡å‹å’Œå£°ç å™¨æ˜¯å¿…éœ€çš„ï¼Œå‰ç«¯æ¨¡å‹å¯é€‰ï¼‰
    if (!modelAssets.acoustic.model || !modelAssets.vocoder.model) {
      console.warn('âš ï¸ PaddleSpeechå¿…éœ€æ¨¡å‹æ–‡ä»¶æœªæ‰¾åˆ°ï¼Œå°†ä½¿ç”¨æ¨¡æ‹Ÿæ¨¡å¼');
      // è®¾ç½®æ¨¡æ‹Ÿæ¨¡å¼æ ‡å¿—
      this.isInitialized = true;
      this.setStatus('loaded');
      return;
    }
    
    try {
      // 1. åŠ è½½æ–‡æœ¬å‰ç«¯æ¨¡å‹ï¼ˆå¯é€‰ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™ä½¿ç”¨ä»£ç å®ç°çš„å‰ç«¯å¤„ç†ï¼‰
      if (modelAssets.frontend.model) {
        this.frontendSession = await this.ort.InferenceSession.create(
          modelAssets.frontend.model
        );
        console.log('âœ… å‰ç«¯æ¨¡å‹å·²åŠ è½½');
      } else {
        console.log('â„¹ï¸ å‰ç«¯æ¨¡å‹æœªæ‰¾åˆ°ï¼Œå°†ä½¿ç”¨ä»£ç å®ç°çš„å‰ç«¯å¤„ç†');
        this.frontendSession = null;
      }
      
      // 2. åŠ è½½å£°å­¦æ¨¡å‹ï¼ˆå¿…éœ€ï¼‰
      this.acousticSession = await this.ort.InferenceSession.create(
        modelAssets.acoustic.model
      );
      console.log('âœ… å£°å­¦æ¨¡å‹å·²åŠ è½½');
      
      // 3. åŠ è½½å£°ç å™¨ï¼ˆå¿…éœ€ï¼‰
      this.vocoderSession = await this.ort.InferenceSession.create(
        modelAssets.vocoder.model
      );
      console.log('âœ… å£°ç å™¨æ¨¡å‹å·²åŠ è½½');
    } catch (error) {
      console.error('åŠ è½½ONNXæ¨¡å‹å¤±è´¥:', error);
      // æ¨¡å‹åŠ è½½å¤±è´¥æ—¶ï¼Œä¸æŠ›å‡ºé”™è¯¯ï¼Œè€Œæ˜¯è¿›å…¥æ¨¡æ‹Ÿæ¨¡å¼
      console.warn('âš ï¸ æ¨¡å‹åŠ è½½å¤±è´¥ï¼Œå°†ä½¿ç”¨æ¨¡æ‹Ÿæ¨¡å¼');
      this.isInitialized = true;
      this.setStatus('loaded');
      return;
    }
  }

  private async loadModelAssets() {
    // ä»assetsåŠ è½½æ¨¡å‹æ–‡ä»¶
      // æ³¨æ„ï¼šæ¨¡å‹æ–‡ä»¶éœ€è¦æ”¾åœ¨ assets/tts-models/paddlespeech-lite/ ç›®å½•ä¸‹
      // åœ¨ Expo ä¸­ï¼Œéœ€è¦ä½¿ç”¨ Asset API æ¥æ­£ç¡®åŠ è½½ assets ç›®å½•çš„æ–‡ä»¶
      try {
        console.log('ğŸ” å¼€å§‹åŠ è½½æ¨¡å‹èµ„æº...');
        
      // æ³¨æ„ï¼šrequire() å¿…é¡»ä½¿ç”¨é™æ€å­—ç¬¦ä¸²è·¯å¾„ï¼Œä¸èƒ½ä½¿ç”¨å˜é‡
      // Metro bundler éœ€è¦åœ¨ç¼–è¯‘æ—¶è§£æä¾èµ–
      // è·¯å¾„å±‚çº§ï¼šä» src/modules/TTSModule/models/ å‘ä¸Š4çº§(../../../../)åˆ° mobile/ï¼Œç„¶åè¿›å…¥ assets/
      const FRONTEND_CONFIG_PATH = '../../../../assets/tts-models/paddlespeech-lite/frontend/config.json';
      const ACOUSTIC_CONFIG_PATH = '../../../../assets/tts-models/paddlespeech-lite/acoustic/config.json';
      const VOCODER_CONFIG_PATH = '../../../../assets/tts-models/paddlespeech-lite/vocoder/config.json';
      const FRONTEND_MODEL_PATH = '../../../../assets/tts-models/paddlespeech-lite/frontend/model.onnx';
      const ACOUSTIC_MODEL_PATH = '../../../../assets/tts-models/paddlespeech-lite/acoustic/model.onnx';
      const VOCODER_MODEL_PATH = '../../../../assets/tts-models/paddlespeech-lite/vocoder/model.onnx';
      
      // 1. åŠ è½½é…ç½®æ–‡ä»¶ï¼ˆJSON æ–‡ä»¶ï¼‰
      let frontendConfig: any = null;
      let acousticConfig: any = null;
      let vocoderConfig: any = null;
      
      // å°è¯•ä½¿ç”¨ require åŠ è½½ï¼ˆå¼€å‘ç¯å¢ƒé€šå¸¸å¯ä»¥å·¥ä½œï¼‰
      // æ³¨æ„ï¼šå¿…é¡»ä½¿ç”¨å­—ç¬¦ä¸²å­—é¢é‡ï¼Œä¸èƒ½ä½¿ç”¨å˜é‡
      // è·¯å¾„å±‚çº§ï¼šä» src/modules/TTSModule/models/ å‘ä¸Š4çº§åˆ° mobile/ï¼Œç„¶åè¿›å…¥ assets/
      try {
        console.log('ğŸ“‚ å°è¯•åŠ è½½å‰ç«¯é…ç½®:', FRONTEND_CONFIG_PATH);
        frontendConfig = require('../../../../assets/tts-models/paddlespeech-lite/frontend/config.json');
        console.log('âœ… å‰ç«¯é…ç½®åŠ è½½æˆåŠŸ');
      } catch (error: any) {
        console.warn('âš ï¸ å‰ç«¯é…ç½®åŠ è½½å¤±è´¥:', error?.message || error);
        console.warn('   å°è¯•çš„è·¯å¾„:', FRONTEND_CONFIG_PATH);
      }
      
      try {
        console.log('ğŸ“‚ å°è¯•åŠ è½½å£°å­¦é…ç½®:', ACOUSTIC_CONFIG_PATH);
        acousticConfig = require('../../../../assets/tts-models/paddlespeech-lite/acoustic/config.json');
        console.log('âœ… å£°å­¦é…ç½®åŠ è½½æˆåŠŸ');
      } catch (error: any) {
        console.warn('âš ï¸ å£°å­¦é…ç½®åŠ è½½å¤±è´¥:', error?.message || error);
        console.warn('   å°è¯•çš„è·¯å¾„:', ACOUSTIC_CONFIG_PATH);
      }
      
      try {
        console.log('ğŸ“‚ å°è¯•åŠ è½½å£°ç å™¨é…ç½®:', VOCODER_CONFIG_PATH);
        vocoderConfig = require('../../../../assets/tts-models/paddlespeech-lite/vocoder/config.json');
        console.log('âœ… å£°ç å™¨é…ç½®åŠ è½½æˆåŠŸ');
      } catch (error: any) {
        console.warn('âš ï¸ å£°ç å™¨é…ç½®åŠ è½½å¤±è´¥:', error?.message || error);
        console.warn('   å°è¯•çš„è·¯å¾„:', VOCODER_CONFIG_PATH);
      }
      
      // 2. åŠ è½½ ONNX æ¨¡å‹æ–‡ä»¶
      // ä½¿ç”¨åŸç”Ÿæ¨¡å—ä» assets å¤åˆ¶æ–‡ä»¶åˆ° documentDirectory
      
      let frontendModelPath: string | null = null;
      let acousticModelPath: string | null = null;
      let vocoderModelPath: string | null = null;
      
      // è¾…åŠ©å‡½æ•°ï¼šè°ƒç”¨åŸç”Ÿæ¨¡å—å¤åˆ¶æ¨¡å‹æ–‡ä»¶
      const copyModelsFromAssets = async (): Promise<boolean> => {
        try {
          if (!ModelFileCopier || Platform.OS !== 'android') {
            if (__DEV__) {
              console.warn('âš ï¸ ModelFileCopier åŸç”Ÿæ¨¡å—ä¸å¯ç”¨ï¼ˆé Android å¹³å°æˆ–æ¨¡å—æœªåŠ è½½ï¼‰');
            }
            return false;
          }
          
          if (__DEV__) {
            console.log('ğŸ“‚ è°ƒç”¨åŸç”Ÿæ¨¡å—å¤åˆ¶æ¨¡å‹æ–‡ä»¶...');
          }
          
          const copier = ModelFileCopier as ModelFileCopierModule;
          const success = await copier.copyModels();
          
          if (success) {
            if (__DEV__) {
              console.log('âœ… æ¨¡å‹æ–‡ä»¶å¤åˆ¶æˆåŠŸ');
            }
            return true;
          } else {
            if (__DEV__) {
              console.warn('âš ï¸ æ¨¡å‹æ–‡ä»¶å¤åˆ¶è¿”å› false');
            }
            return false;
          }
        } catch (error: any) {
          // è¾“å‡ºè¯¦ç»†é”™è¯¯ä¿¡æ¯ï¼Œå¸®åŠ©è°ƒè¯•
          const errorMessage = error?.message || String(error);
          const errorCode = error?.code || '';
          console.error('âŒ å¤åˆ¶æ¨¡å‹æ–‡ä»¶å¤±è´¥:', errorMessage);
          if (errorCode) {
            console.error('   é”™è¯¯ä»£ç :', errorCode);
          }
          if (error?.userInfo || error?.nativeStackAndroid) {
            console.error('   è¯¦ç»†ä¿¡æ¯:', JSON.stringify(error?.userInfo || error?.nativeStackAndroid));
          }
          return false;
        }
      };
      
      // å°è¯•å¤åˆ¶æ¨¡å‹æ–‡ä»¶ï¼ˆå¦‚æœéœ€è¦ï¼‰
      if (Platform.OS === 'android' && FileSystem.documentDirectory) {
        const targetBasePath = FileSystem.documentDirectory + 'assets/tts-models/paddlespeech-lite/';
        
        // æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å·²å­˜åœ¨
        const frontendTargetPath = targetBasePath + 'frontend/model.onnx';
        const acousticTargetPath = targetBasePath + 'acoustic/model.onnx';
        const vocoderTargetPath = targetBasePath + 'vocoder/model.onnx';
        
        try {
          const frontendExists = (await FileSystem.getInfoAsync(frontendTargetPath)).exists;
          const acousticExists = (await FileSystem.getInfoAsync(acousticTargetPath)).exists;
          const vocoderExists = (await FileSystem.getInfoAsync(vocoderTargetPath)).exists;
          
          // å¦‚æœæ–‡ä»¶ä¸å­˜åœ¨ï¼Œè°ƒç”¨åŸç”Ÿæ¨¡å—å¤åˆ¶
          if (!frontendExists || !acousticExists || !vocoderExists) {
            if (__DEV__) {
              console.log('ğŸ“¦ æ£€æµ‹åˆ°æ¨¡å‹æ–‡ä»¶ç¼ºå¤±ï¼Œå¼€å§‹å¤åˆ¶...');
            }
            
            // é¦–å…ˆå°è¯•ä½¿ç”¨åŸç”Ÿæ¨¡å—å¤åˆ¶ï¼ˆä» APK assetsï¼‰
            const nativeCopySuccess = await copyModelsFromAssets();
            
            // å¦‚æœåŸç”Ÿæ¨¡å—å¤åˆ¶å¤±è´¥ï¼Œå°è¯•ä» bundleDirectory å¤åˆ¶ï¼ˆMetro æ‰“åŒ…çš„æ–‡ä»¶ï¼‰
            if (!nativeCopySuccess && FileSystem.bundleDirectory) {
              if (__DEV__) {
                console.log('ğŸ“¦ åŸç”Ÿæ¨¡å—å¤åˆ¶å¤±è´¥ï¼Œå°è¯•ä» bundle ç›®å½•å¤åˆ¶...');
              }
              
              try {
                const bundleBasePath = FileSystem.bundleDirectory.replace(/^asset:\//, '') + 'tts-models/paddlespeech-lite/';
                const modelsToCopy = [
                  { source: bundleBasePath + 'frontend/model.onnx', target: frontendTargetPath },
                  { source: bundleBasePath + 'acoustic/model.onnx', target: acousticTargetPath },
                  { source: bundleBasePath + 'vocoder/model.onnx', target: vocoderTargetPath },
                ];
                
                let bundleCopyCount = 0;
                for (const { source, target } of modelsToCopy) {
                  try {
                    // æ£€æŸ¥æºæ–‡ä»¶æ˜¯å¦å­˜åœ¨
                    const sourceInfo = await FileSystem.getInfoAsync(source);
                    if (!sourceInfo.exists) {
                      if (__DEV__) {
                        console.warn(`âš ï¸ Bundle æºæ–‡ä»¶ä¸å­˜åœ¨: ${source}`);
                      }
                      continue;
                    }
                    
                    // ç¡®ä¿ç›®æ ‡ç›®å½•å­˜åœ¨
                    const targetDir = target.substring(0, target.lastIndexOf('/'));
                    const dirInfo = await FileSystem.getInfoAsync(targetDir);
                    if (!dirInfo.exists) {
                      await FileSystem.makeDirectoryAsync(targetDir, { intermediates: true });
                    }
                    
                    // è¯»å–æºæ–‡ä»¶ï¼ˆbase64ï¼‰
                    const sourceData = await FileSystem.readAsStringAsync(source, {
                      encoding: 'base64' as any,
                    });
                    
                    // å†™å…¥ç›®æ ‡æ–‡ä»¶
                    await FileSystem.writeAsStringAsync(target, sourceData, {
                      encoding: 'base64' as any,
                    });
                    
                    bundleCopyCount++;
                    if (__DEV__) {
                      console.log(`âœ… ä» bundle å¤åˆ¶æˆåŠŸ: ${target.substring(target.lastIndexOf('/') + 1)}`);
                    }
                  } catch (error: any) {
                    if (__DEV__) {
                      console.warn(`âš ï¸ ä» bundle å¤åˆ¶å¤±è´¥ ${source}:`, error?.message || error);
                    }
                  }
                }
                
                if (bundleCopyCount > 0 && __DEV__) {
                  console.log(`âœ… ä» bundle ç›®å½•æˆåŠŸå¤åˆ¶ ${bundleCopyCount} ä¸ªæ¨¡å‹æ–‡ä»¶`);
                }
              } catch (error: any) {
                if (__DEV__) {
                  console.warn('âš ï¸ ä» bundle ç›®å½•å¤åˆ¶æ—¶å‡ºé”™:', error?.message || error);
                }
              }
            }
          }
          
          // ç°åœ¨å°è¯•è¯»å–æ–‡ä»¶è·¯å¾„
          if ((await FileSystem.getInfoAsync(frontendTargetPath)).exists) {
            frontendModelPath = frontendTargetPath;
            if (__DEV__) {
              console.log('âœ… å‰ç«¯æ¨¡å‹è·¯å¾„:', frontendModelPath);
            }
          }
          
          if ((await FileSystem.getInfoAsync(acousticTargetPath)).exists) {
            acousticModelPath = acousticTargetPath;
            if (__DEV__) {
              console.log('âœ… å£°å­¦æ¨¡å‹è·¯å¾„:', acousticModelPath);
            }
          }
          
          if ((await FileSystem.getInfoAsync(vocoderTargetPath)).exists) {
            vocoderModelPath = vocoderTargetPath;
            if (__DEV__) {
              console.log('âœ… å£°ç å™¨æ¨¡å‹è·¯å¾„:', vocoderModelPath);
            }
          }
        } catch (error: any) {
          if (__DEV__) {
            console.warn('âš ï¸ æ£€æŸ¥æˆ–å¤åˆ¶æ¨¡å‹æ–‡ä»¶æ—¶å‡ºé”™:', error?.message || error);
          }
        }
      } else {
        if (__DEV__) {
          console.warn('âš ï¸ é Android å¹³å°æˆ– documentDirectory ä¸å¯ç”¨ï¼Œæ— æ³•å¤åˆ¶æ¨¡å‹æ–‡ä»¶');
        }
      }
      
      // æ£€æŸ¥æ˜¯å¦è‡³å°‘æœ‰ä¸€äº›æ–‡ä»¶åŠ è½½æˆåŠŸ
      const hasAnyConfig = frontendConfig || acousticConfig || vocoderConfig;
      const hasAnyModel = frontendModelPath || acousticModelPath || vocoderModelPath;
      
      if (!hasAnyConfig && !hasAnyModel) {
        console.warn('âš ï¸ PaddleSpeechæ¨¡å‹æ–‡ä»¶æœªæ‰¾åˆ°ï¼Œå°†ä½¿ç”¨æ¨¡æ‹Ÿæ¨¡å¼');
        console.warn('æç¤ºï¼šç¡®ä¿æ¨¡å‹æ–‡ä»¶å­˜åœ¨äº assets/tts-models/paddlespeech-lite/ ç›®å½•');
        return {
          frontend: { model: null, config: null },
          acoustic: { model: null, config: null },
          vocoder: { model: null, config: null }
        };
      }
      
      console.log('ğŸ“¦ æ¨¡å‹èµ„æºåŠ è½½å®Œæˆ:', {
        frontend: { config: !!frontendConfig, model: !!frontendModelPath },
        acoustic: { config: !!acousticConfig, model: !!acousticModelPath },
        vocoder: { config: !!vocoderConfig, model: !!vocoderModelPath }
      });
      
      return {
        frontend: {
          model: frontendModelPath,
          config: frontendConfig
        },
        acoustic: {
          model: acousticModelPath,
          config: acousticConfig
        },
        vocoder: {
          model: vocoderModelPath,
          config: vocoderConfig
        }
      };
    } catch (error: any) {
      console.error('âŒ åŠ è½½æ¨¡å‹èµ„æºæ—¶å‘ç”Ÿé”™è¯¯:', error);
      console.warn('âš ï¸ å°†ä½¿ç”¨æ¨¡æ‹Ÿæ¨¡å¼');
      return {
        frontend: { model: null, config: null },
        acoustic: { model: null, config: null },
        vocoder: { model: null, config: null }
      };
    }
  }

  async synthesize(text: string, config?: Partial<TTSModelConfig>): Promise<TTSResult> {
    try {
      this.validateText(text);
      
      if (!this.isInitialized) {
        throw new Error('æ¨¡å‹æœªåˆå§‹åŒ–');
      }

      const startTime = Date.now();
      
      // æ›´æ–°é…ç½®
      if (config) {
        this.updateConfig(config);
      }

      console.log('ğŸ”Š å¼€å§‹PaddleSpeechè¯­éŸ³åˆæˆ:', text.substring(0, 30) + '...');
      
      // æ£€æŸ¥å¿…éœ€çš„æ¨¡å‹æ˜¯å¦çœŸå®åŠ è½½ï¼ˆå‰ç«¯æ¨¡å‹å¯é€‰ï¼‰
      if (!this.acousticSession || !this.vocoderSession) {
        // æ¨¡æ‹Ÿæ¨¡å¼ï¼šè¿”å›æ¨¡æ‹Ÿçš„éŸ³é¢‘æ•°æ®
        console.warn('âš ï¸ ä½¿ç”¨æ¨¡æ‹Ÿæ¨¡å¼ç”ŸæˆéŸ³é¢‘ï¼ˆå¿…éœ€æ¨¡å‹æ–‡ä»¶æœªåŠ è½½ï¼‰');
        return this.generateMockAudio(text, startTime);
      }
      
      // 1. æ–‡æœ¬å¤„ç†
      const textFeatures = await this.processText(text);
      
      // 2. å£°å­¦æ¨¡å‹ç”Ÿæˆæ¢…å°”é¢‘è°±
      const melSpectrogram = await this.runAcousticModel(textFeatures);
      
      // 3. å£°ç å™¨ç”Ÿæˆæ³¢å½¢
      const audioData = await this.runVocoder(melSpectrogram);
      
      const synthesisTime = Date.now() - startTime;
      
      const result: TTSResult = {
        audioData: this.audioArrayToDataURL(audioData),
        duration: this.calculateDuration(text),
        sampleRate: this.sampleRate,
        format: 'wav',
        timestamp: Date.now(),
        synthesisTime
      };

      console.log(`ğŸ”Š PaddleSpeechåˆæˆå®Œæˆ: ${synthesisTime}ms`);
      
      // æ€§èƒ½æ£€æŸ¥
      if (synthesisTime > 150) { // ç¨å¾®æ”¾å®½åˆ°150ms
        console.warn(`åˆæˆæ—¶é—´ ${synthesisTime}ms è¶…è¿‡æ¨èå€¼`);
      }
      
      return result;
      
    } catch (error) {
      console.error('PaddleSpeechåˆæˆå¤±è´¥:', error);
      throw new Error(`åˆæˆå¤±è´¥: ${error instanceof Error ? error.message : 'æœªçŸ¥é”™è¯¯'}`);
    }
  }

  /**
   * ç”Ÿæˆæ¨¡æ‹ŸéŸ³é¢‘ï¼ˆç”¨äºæµ‹è¯•ï¼Œå½“æ¨¡å‹æ–‡ä»¶æœªåŠ è½½æ—¶ï¼‰
   * æ³¨æ„ï¼šè¿”å›ç©ºå­—ç¬¦ä¸²ä½œä¸º audioDataï¼Œè§¦å‘ç³»ç»Ÿ TTS å›é€€
   */
  private generateMockAudio(text: string, startTime: number): TTSResult {
    // ä¸å†ç”Ÿæˆæ— æ•ˆçš„éŸ³é¢‘æ•°æ®ï¼Œè€Œæ˜¯è¿”å›ç©ºæ•°æ®
    // è¿™æ · TTSModule ä¼šæ£€æµ‹åˆ°å¹¶å›é€€åˆ°ç³»ç»Ÿ TTS
    const duration = this.calculateDuration(text);
    const synthesisTime = Date.now() - startTime;
    
    if (__DEV__) {
      console.log('âš ï¸ æ¨¡æ‹Ÿæ¨¡å¼ï¼šè¿”å›ç©ºéŸ³é¢‘æ•°æ®ï¼Œå°†è§¦å‘ç³»ç»Ÿ TTS å›é€€');
    }
    
    return {
      audioData: '', // è¿”å›ç©ºå­—ç¬¦ä¸²ï¼Œè§¦å‘å›é€€åˆ°ç³»ç»Ÿ TTS
      duration,
      sampleRate: this.sampleRate,
      format: 'wav',
      timestamp: Date.now(),
      synthesisTime
    };
  }

  private async processText(text: string): Promise<any> {
    // æ–‡æœ¬å¤„ç†ï¼šå¦‚æœæœ‰å‰ç«¯æ¨¡å‹åˆ™ä½¿ç”¨ï¼Œå¦åˆ™ä½¿ç”¨ä»£ç å®ç°
    let textIds: number[];
    
    if (this.frontendSession) {
      // ä½¿ç”¨å‰ç«¯æ¨¡å‹å¤„ç†æ–‡æœ¬
      const textTensor = new this.ort.Tensor('string', [text], [1]);
      const results = await this.frontendSession.run({ text: textTensor });
      textIds = Array.from(results.phone_ids.data);
    } else {
      // ä½¿ç”¨ä»£ç å®ç°çš„å‰ç«¯å¤„ç†ï¼ˆåŸºäºphone_id_map.txtï¼‰
      textIds = this.textToIds(text);
    }
    
    const textTensor = new this.ort.Tensor(
      'int64',
      textIds,
      [1, textIds.length]
    );
    
    return { input_ids: textTensor };
  }

  private textToIds(text: string): number[] {
    // å°†æ–‡æœ¬è½¬æ¢ä¸ºéŸ³ç´ IDåºåˆ—
    // ä½¿ç”¨phone_id_map.txtè¿›è¡Œæ˜ å°„ï¼ˆå¦‚æœå¯ç”¨ï¼‰
    // ç®€åŒ–å®ç°ï¼šä½¿ç”¨å­—ç¬¦ç¼–ç æ˜ å°„
    // æ³¨æ„ï¼šå®é™…åº”è¯¥ä½¿ç”¨å®Œæ•´çš„G2Pï¼ˆå­—ç´ åˆ°éŸ³ç´ ï¼‰è½¬æ¢
    try {
      // å°è¯•åŠ è½½phone_id_mapï¼ˆå¦‚æœå­˜åœ¨ï¼‰
      // æ³¨æ„ï¼šrequire() å¿…é¡»ä½¿ç”¨é™æ€å­—ç¬¦ä¸²è·¯å¾„ï¼Œä¸èƒ½ä½¿ç”¨å˜é‡
      // è·¯å¾„å±‚çº§ï¼šä» src/modules/TTSModule/models/ å‘ä¸Š4çº§åˆ° mobile/ï¼Œç„¶åè¿›å…¥ assets/
      const phoneIdMap = require('../../../../assets/tts-models/paddlespeech-lite/acoustic/phone_id_map.txt');
      // è¿™é‡Œéœ€è¦è§£æphone_id_map.txtå¹¶æ˜ å°„
      // ç®€åŒ–å®ç°ï¼šç›´æ¥ä½¿ç”¨å­—ç¬¦ç¼–ç 
    } catch (e) {
      // phone_id_mapä¸å¯ç”¨ï¼Œä½¿ç”¨ç®€åŒ–æ˜ å°„
    }
    
    // ç®€åŒ–å¤„ç†ï¼šå°†ä¸­æ–‡å­—ç¬¦è½¬æ¢ä¸ºIDï¼ˆå®é™…åº”è¯¥ä½¿ç”¨G2Pï¼‰
    return text.split('').map(char => {
      const code = char.charCodeAt(0);
      // ä¸­æ–‡å­—ç¬¦èŒƒå›´ï¼š0x4E00-0x9FFF
      if (code >= 0x4E00 && code <= 0x9FFF) {
        return (code - 0x4E00) % 200 + 1; // æ˜ å°„åˆ°1-200èŒƒå›´
      }
      return code % 1000;
    });
  }

  /**
   * è®¡ç®—éŸ³é¢‘æ—¶é•¿ï¼ˆä¼°ç®—ï¼‰
   */
  protected calculateDuration(text: string): number {
    // ä¸­æ–‡å¹³å‡è¯­é€Ÿçº¦4å­—/ç§’
    const charsPerSecond = 4;
    const duration = (text.length / charsPerSecond) * 1000;
    return Math.max(500, Math.min(duration, 30000)); // é™åˆ¶åœ¨0.5-30ç§’ä¹‹é—´
  }

  private async runAcousticModel(features: any): Promise<any> {
    // è¿è¡Œå£°å­¦æ¨¡å‹
    const feeds = { 
      text: features.input_ids 
    };
    
    const results = await this.acousticSession.run(feeds);
    return results.output;
  }

  private async runVocoder(melSpectrogram: any): Promise<Float32Array> {
    // è¿è¡Œå£°ç å™¨ç”ŸæˆéŸ³é¢‘æ³¢å½¢
    const feeds = { 
      logmel: melSpectrogram 
    };
    
    const results = await this.vocoderSession.run(feeds);
    return results.waveform.data;
  }

  private audioArrayToDataURL(audioData: Float32Array): string {
    // å°†Float32ArrayéŸ³é¢‘æ•°æ®è½¬æ¢ä¸ºWAVæ ¼å¼çš„Data URL
    const wavData = this.createWavBuffer(audioData, this.sampleRate);
    const base64 = this.arrayBufferToBase64(wavData);
    return `data:audio/wav;base64,${base64}`;
  }

  private createWavBuffer(audioData: Float32Array, sampleRate: number): ArrayBuffer {
    // åˆ›å»ºWAVæ ¼å¼çš„éŸ³é¢‘ç¼“å†²åŒº
    // WAV æ–‡ä»¶ç»“æ„ï¼š
    // - RIFF header (12 bytes): 'RIFF' + chunkSize + 'WAVE'
    // - fmt chunk (24 bytes): 'fmt ' + fmtSize (16) + format data
    // - data chunk (8 + dataSize): 'data' + dataSize + PCM data
    const dataSize = audioData.length * 2; // 16-bit PCM = 2 bytes per sample
    const fmtChunkSize = 16; // PCM format chunk size
    // RIFF chunk size = æ–‡ä»¶å¤§å° - 8 (å‡å» 'RIFF' 4å­—èŠ‚ + chunkSize 4å­—èŠ‚)
    // æ–‡ä»¶ç»“æ„: RIFF header (12) + fmt chunk (24) + data chunk (8 + dataSize) = 44 + dataSize
    // æ‰€ä»¥ RIFF chunk size = (44 + dataSize) - 8 = 36 + dataSize
    const riffChunkSize = 36 + dataSize;
    const buffer = new ArrayBuffer(44 + dataSize);
    const view = new DataView(buffer);
    
    // RIFF header (0-11)
    this.writeString(view, 0, 'RIFF');           // 0-3: 'RIFF'
    view.setUint32(4, riffChunkSize, true);      // 4-7: chunk size (æ–‡ä»¶å¤§å° - 8)
    this.writeString(view, 8, 'WAVE');           // 8-11: 'WAVE'
    
    // fmt chunk (12-35)
    this.writeString(view, 12, 'fmt ');          // 12-15: 'fmt ' (æ³¨æ„æœ«å°¾æœ‰ç©ºæ ¼)
    view.setUint32(16, fmtChunkSize, true);      // 16-19: fmt chunk size (16 for PCM)
    view.setUint16(20, 1, true);                 // 20-21: audio format (1 = PCM)
    view.setUint16(22, 1, true);                 // 22-23: num channels (1 = mono)
    view.setUint32(24, sampleRate, true);        // 24-27: sample rate
    view.setUint32(28, sampleRate * 2, true);    // 28-31: byte rate (sampleRate * numChannels * bitsPerSample/8)
    view.setUint16(32, 2, true);                 // 32-33: block align (numChannels * bitsPerSample/8)
    view.setUint16(34, 16, true);                // 34-35: bits per sample (16-bit)
    
    // data chunk (36-43)
    this.writeString(view, 36, 'data');          // 36-39: 'data'
    view.setUint32(40, dataSize, true);          // 40-43: data chunk size
    
    // PCMæ•°æ® (44+)
    // å°† Float32 (-1.0 åˆ° 1.0) è½¬æ¢ä¸º Int16 (-32768 åˆ° 32767)
    let offset = 44;
    for (let i = 0; i < audioData.length; i++) {
      // é™åˆ¶èŒƒå›´å¹¶è½¬æ¢
      let sample = Math.max(-1.0, Math.min(1.0, audioData[i]));
      
      // è½¬æ¢ä¸º 16-bit signed integer (-32768 to 32767)
      // æ ‡å‡†åšæ³•ï¼šå°† [-1.0, 1.0] æ˜ å°„åˆ° [-32768, 32767]
      // å¯¹äºè´Ÿæ•°ä½¿ç”¨ 32768ï¼Œå¯¹äºæ­£æ•°ä½¿ç”¨ 32767ï¼Œä»¥ç¡®ä¿å¯¹ç§°æ˜ å°„
      let int16Sample: number;
      if (sample < 0) {
        int16Sample = Math.round(sample * 32768);
        // ç¡®ä¿ä¸è¶…è¿‡ -32768
        int16Sample = Math.max(-32768, int16Sample);
      } else {
        int16Sample = Math.round(sample * 32767);
        // ç¡®ä¿ä¸è¶…è¿‡ 32767
        int16Sample = Math.min(32767, int16Sample);
      }
      
      view.setInt16(offset, int16Sample, true);  // little-endian
      offset += 2;
    }
    
    return buffer;
  }

  private writeString(view: DataView, offset: number, string: string): void {
    for (let i = 0; i < string.length; i++) {
      view.setUint8(offset + i, string.charCodeAt(i));
    }
  }

  private arrayBufferToBase64(buffer: ArrayBuffer): string {
    return base64Encode(buffer);
  }

  async unloadModel(): Promise<void> {
    if (this.frontendSession) {
      this.frontendSession.release();
      this.frontendSession = null;
    }
    if (this.acousticSession) {
      this.acousticSession.release();
      this.acousticSession = null;
    }
    if (this.vocoderSession) {
      this.vocoderSession.release();
      this.vocoderSession = null;
    }
    
    this.isInitialized = false;
    this.setStatus('unloaded');
    
    console.log('ğŸ”Š PaddleSpeechæ¨¡å‹å·²å¸è½½');
  }
}